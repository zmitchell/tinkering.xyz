<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hardware on Tinkering.xyz</title>
    <link>http://tinkering.xyz/tags/hardware/index.xml</link>
    <description>Recent content in Hardware on Tinkering.xyz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="http://tinkering.xyz/tags/hardware/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How Hyperthreading Works ... I Think</title>
      <link>http://tinkering.xyz/posts/hyperthreading/</link>
      <pubDate>Fri, 17 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://tinkering.xyz/posts/hyperthreading/</guid>
      <description>&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt; - A hyperthreading-enabled processor reports to the operating system that it is actually two separate processors so that the CPU assumes the responsibility of deciding when it should schedule work to be done on multiple jobs running at the same time. The CPU is much more efficient than the operating system at this decision making process, which allows it to better manage its time and resources. In some cases this results in doubled performance, but in others it doesn’t increase performance at all. The type of work being done by the processor is a large deciding factor in whether hyperthreading increases performance.&lt;/p&gt;

&lt;p&gt;In my last post I talked about buying a development machine. Since I&amp;rsquo;ll be doing a lot of compiling on this machine the particular CPU installed was one of the details I focused on most. Some of the available processors offered what Intel calls &amp;ldquo;Hyperthreading&amp;rdquo; (HT). This is something that Intel still uses today. In broad strokes, Intel&amp;rsquo;s desktop processor lineup looks like this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;i3 - 2 cores with HT&lt;/li&gt;
&lt;li&gt;i5 - 4 cores without HT&lt;/li&gt;
&lt;li&gt;i7 - 4 or more cores with HT&lt;br /&gt;

&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While doing some research on this topic I found an &lt;a href=&#34;http://www.sheepguardingllama.com/2008/03/cpus-cores-and-threads-how-many-processors-do-i-have/&#34;&gt;article&lt;/a&gt; that clarifies the distinction between a CPU, a processor, and a core. The article is nearly 10 years old at this point, but I learned a few things and found it to still be relevant.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s get back to the discussion of HT. A processor with &lt;code&gt;N&lt;/code&gt; physical processor cores supports &lt;code&gt;N&lt;/code&gt; threads without HT, or &lt;code&gt;2N&lt;/code&gt; threads with HT. A CPU &lt;a href=&#34;https://arstechnica.com/business/2011/04/ask-ars-what-is-a-cpu-thread/&#34;&gt;thread&lt;/a&gt; is basically a pipeline of instructions that are fed to the CPU.  Intel&amp;rsquo;s &lt;a href=&#34;https://ark.intel.com/m/products/65719/Intel-Core-i7-3770-Processor-8M-Cache-up-to-3_90-GHz&#34;&gt;product pages&lt;/a&gt; are pretty informative, and report the number of threads supported by a given processor. In some places I&amp;rsquo;ve seen threads called &amp;ldquo;logical cores&amp;rdquo; or “logical processors.” In that case a CPU without HT has the same number of logical and physical processor cores, but a CPU that supports HT has twice as many logical cores as physical cores.&lt;/p&gt;

&lt;p&gt;Let’s tie this back to my original question about code compilation. GNU &lt;code&gt;make&lt;/code&gt; allows you to pass it an argument telling it how many parallel jobs to spawn. For example, the following code would allow 4 different jobs to run in parallel during compilation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;$ make -j4
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The documentation for &lt;code&gt;make&lt;/code&gt; tells you to set the argument of the &lt;code&gt;-j&lt;/code&gt; flag to the number of processors. The question then becomes whether &amp;ldquo;processor&amp;rdquo; means physical processor cores or logical processors (CPU threads).&lt;/p&gt;

&lt;p&gt;It turns out I&amp;rsquo;m not the first person to ask this question (go figure). In &lt;a href=&#34;http://stackoverflow.com/questions/2499070/gnu-make-should-the-number-of-jobs-equal-the-number-of-cpu-cores-in-a-system&#34;&gt;this&lt;/a&gt; Stack Overflow post someone asks basically the same question. One of the responders posts compilation times done on a 4-core processor with HT and a variety of parallel job counts.  Before reading about what HT actually is or how it works, I assumed that a CPU that supported HT would be able to do twice as much work as a non-HT CPU since the HT CPU supported two execution threads per physical processor as opposed to a single execution thread per processor in a non-HT CPU. That assumption turns out not to be true.&lt;/p&gt;

&lt;p&gt;Looking at the compilation times in that SO post, there is a big difference in compilation time going from 1-4 jobs (148s vs 59s), a very small difference from 4-8 jobs (59s vs 54s), and basically no difference with more than 8 jobs.&lt;/p&gt;

&lt;p&gt;Regardless of HT, it makes sense that you would see a big speed up going from 1 to 4 jobs since at the very least you have 4 physical processors available to work independently. On the other hand, if the number of execution threads is the bottleneck then you would expect a much bigger speed up than what the poster reported going from 4 to 8 jobs. To understand the discrepancy we have to dig in to the details of how a processor works. I&amp;rsquo;m by no means an expert on this topic, so I&amp;rsquo;m sure that I&amp;rsquo;m glossing over very important details, but I&amp;rsquo;ve tried to explain the following in an accessible way.&lt;/p&gt;

&lt;p&gt;Everything related to feeding instructions to a processor is highly optimized to prevent the processor from having to wait around for instructions. If we think about feeding instructions to the processor through a pipeline, the processor gets the most done when that pipeline is full and the instructions are related to the same thing. The operating system (OS) sees that there is a job that needs to be done, and passes the relevant instructions through the pipeline to the processor.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s complicate matters by saying that there are two jobs that need to be done and they have equal priorities. In the case of a single processor without HT, the OS flips back and forth between telling the processor to work on job 1 and job 2, and each time it does so the processor has to change gears. Clearly this is not the most efficient use of the processor&amp;rsquo;s time, and letting the OS tie itself up trying to figure out which of the two jobs to tell the processor to work on probably isn&amp;rsquo;t doing us any favors.&lt;/p&gt;

&lt;p&gt;Enter hyperthreading. According to &lt;a href=&#34;https://www.percona.com/blog/2015/01/15/hyper-threading-double-cpu-throughput/&#34;&gt;this article&lt;/a&gt;, a processor with HT assumes the responsibility of deciding when to work on which job by essentially faking out the OS. A processor with HT has two instruction pipelines per processor, rather than one, and it fakes out the OS by telling it that each instruction pipeline is a separate processor. Now when the OS has two jobs of equal priority it doesn&amp;rsquo;t have to think about when to work on one or the other, it just hands one job to one &amp;ldquo;processor&amp;rdquo; and the other job to the other &amp;ldquo;processor&amp;rdquo; and lets them get on with it.&lt;/p&gt;

&lt;p&gt;At this point you might be wondering what that accomplishes. Both with or without HT something is deciding when the processor should work on job 1 or job 2. In one case it&amp;rsquo;s the OS, and in the other case it&amp;rsquo;s the processor. The answer lies in the fact that everything gets faster as you get closer to the CPU. Letting the CPU decide which of its instruction pipelines to churn through is much more efficient than letting the OS call the shots. Think of it as walking down to your manager&amp;rsquo;s office to ask a question as opposed to trying to get a meeting with the CEO.&lt;/p&gt;

&lt;p&gt;Now we can tie this back to our code compilation and the reason that you sometimes only see a modest speed improvement with HT. A processor with HT doesn&amp;rsquo;t behave like two complete, separate processors. True, there are two separate pipelines of instructions for the CPU, but you still only have a single CPU and you&amp;rsquo;re limited by how fast it process a single instruction. Compared to a processor without HT, a processor with HT is better at managing its time and resources, but at the end of the day it&amp;rsquo;s still just a single processor.&lt;/p&gt;

&lt;p&gt;However, one thing I’ve completely ignored up to this point is the type of work the CPU is doing. Some work is well-suited to being parallelized, whereas other work doesn’t see any benefit. It seems to me that the most important aspect of this is where the bottleneck lies. &lt;a href=&#34;http://superuser.com/a/279803&#34;&gt;This&lt;/a&gt; SO post discusses this bottleneck effect. The poster runs a variety of algorithms on a HT-enabled CPU, and reports the speedup as a function of the number of threads. For two of the algorithms you see a linear increase all the way up to the maximum number of threads, whereas two other algorithms top out at the number of physical processors. The algorithms that scale with the number of threads are bottlenecked by something other than the processor, which means that the processor can work on one job while the other job is waiting for whatever external resources are causing the bottleneck. The other two algorithms are limited strictly by the CPU, so the ability to put one job on hold while working on the other doesn&amp;rsquo;t provide any benefits.&lt;/p&gt;

&lt;p&gt;One thing to keep in mind with that post is that it reports the speedup relative to a single thread running the same algorithm. In other words, it doesn’t tell you anything about whether one algorithm is faster than another on a single thread, or whether HT makes one algorithm faster than another.&lt;/p&gt;

&lt;p&gt;To wrap up, a hyperthreading-enabled processor reports that it is actually two separate processors to the operating system so that the CPU assumes the responsibility of deciding when it should schedule work to be done on multiple jobs running at the same time. The CPU is much more efficient than the operating system at this decision making process, which allows it to better manage its time and resources. In some cases this results in doubled performance, but in others it doesn’t increase performance at all. The type of work being done by the processor is a large deciding factor in whether hyperthreading increases performance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Development Hardware for a Steal</title>
      <link>http://tinkering.xyz/posts/development-hardware/</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://tinkering.xyz/posts/development-hardware/</guid>
      <description>

&lt;p&gt;Yes, this is posted on Valentine&amp;rsquo;s Day, but my wife is out of town so I have nothing better to do.&lt;/p&gt;

&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;I do all of my programming on my Macbook Pro, but which hardware the code runs on varies. I have a Raspberry Pi 3, a desktop running Windows that’s attached to a Drobo, and my Macbook Pro. Windows isn&amp;rsquo;t *nix based and has no built-in package manager (neither does macOS, but at least it&amp;rsquo;s Unix based), so there&amp;rsquo;s more friction than I would like with regards to programming on Windows. Most of the programming I’ve done for the Pi has involved developing Docker containers with dependencies that must be built from source. This is rage inducing for a number of reasons:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Compiling anything from source on a Pi is glacially slow.&lt;/li&gt;
&lt;li&gt;I connect to the Pi via &lt;code&gt;ssh&lt;/code&gt;, which means that I don’t see any error messages if the connection is interrupted while Docker is building an image.&lt;/li&gt;
&lt;li&gt;I haven’t found a way to have Docker save the output of the build process so that I can look at it later.&lt;br /&gt;

&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of that is to say that I have to be connected to the Pi throughout the entire multi-hour long build process if I want to see the error message at the end. What if I start the build process at work and need to go home while it’s still building? I decided that I wanted to spend more time programming and less time &lt;a href=&#34;https://en.wiktionary.org/wiki/yak_shaving&#34;&gt;yak shaving&lt;/a&gt;, so I started looking at what kind of computer I could get for what kind of money.&lt;/p&gt;

&lt;h1 id=&#34;the-search&#34;&gt;The Search&lt;/h1&gt;

&lt;p&gt;The first thing I did was pick a bunch of new parts on Newegg and see how much it came out to. For a Skylake i5 processor, some DDR4 RAM, a small SSD, and some mini-ITX parts the build came out to about $500. I didn’t want to spend that much on a computer that would only be marginally faster than my current desktop, so I started looking around on eBay.&lt;/p&gt;

&lt;p&gt;I eventually discovered that you can buy used servers on eBay for $200-$300. When you consider that the available servers typically come with two processors, each of which is either 4-core or 6-core, and somewhere in the range of 16GB-48GB of RAM, an old server becomes a pretty enticing option with regards to bang for your buck.&lt;/p&gt;

&lt;p&gt;The first thing I realized while browsing used servers on eBay was that I had no idea what I was looking at. I, like lots of other nerds, have built my own desktop from scratch, but that did basically nothing to educate me about server hardware. After poking around on the internet for a little while I found &lt;a href=&#34;https://www.reddit.com/r/homelab/&#34;&gt;/r/homelab&lt;/a&gt;, which is a subreddit for people who want to build their own quasi-enterprise-level computer lab at home. The wiki there has a bunch of information about which servers to buy, which to avoid, etc. More importantly, it provides a warning about the downsides of these servers.&lt;/p&gt;

&lt;p&gt;Most of these servers are several years old, so their processors haven’t reaped benefits from recent advancements in power efficiency. These servers were also designed to keep their internals cool in an environment where you have lots of heat-producing hardware running at full-bore while stuffed in a small box next to a bunch of other small boxes that are also spewing heat. Needless to say, you need a lot of beefy fans to keep things cool in that kind of environment. This means that some servers sound like small jets taking off. Another issue is that the hard drives used in servers are typically not the same hard drives that you would find in a desktop computer. Server hard drives use &lt;a href=&#34;https://en.wikipedia.org/wiki/Serial_Attached_SCSI&#34;&gt;SAS&lt;/a&gt; rather than &lt;a href=&#34;https://en.wikipedia.org/wiki/Serial_ATA&#34;&gt;SATA&lt;/a&gt;, and typically spin at 10k-15k RPM compared to 5.4k-7.2k like consumer hard drives. The read/write speed of a hard drive increases with the rate at which the disk spins, but the power consumption increases as well.&lt;/p&gt;

&lt;p&gt;On top of that, some of the processors that you&amp;rsquo;ll find in these servers don&amp;rsquo;t have support for Intel&amp;rsquo;s AES-NI instructions (see &lt;a href=&#34;https://en.wikipedia.org/wiki/AES_instruction_set&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://crypto.stackexchange.com/questions/19544/how-exactly-does-aes-ni-work&#34;&gt;here&lt;/a&gt;), which provide hardware acceleration for certain encryption related tasks. Just to be clear, you can still do encryption related tasks with processors that don&amp;rsquo;t support the AES-NI instruction set, it will just be much faster on processors that &lt;strong&gt;do&lt;/strong&gt; support the AES-NI instruction set.&lt;/p&gt;

&lt;p&gt;Put all of that together and you have older, less efficient processors, a bunch of loud fans running at full speed all the time, and a bunch of hard drives that consume more power than your average consumer hard drive. The power consumption of a server like this can be anywhere from 140W-175W &lt;strong&gt;at idle&lt;/strong&gt;, but as high as 250W at full load. I did a quick calculation based on the cost of electricity from my last electric bill, and a server consuming 140W at idle would cost about $15/month in electricity alone. That’s $180/year, which is a considerable fraction of the cost of the server itself. With that in mind, I decided to see what else I could get for a similar amount of money.&lt;/p&gt;

&lt;h1 id=&#34;what-i-bought&#34;&gt;What I Bought&lt;/h1&gt;

&lt;p&gt;I eventually found some workstations built around Xeon E5-2660/E5-2670 processors, which are slightly newer 8-core server processors with performance only slightly lower than that of the fastest servers that I was looking at before. The workstations only come with 1 processor, but the motherboards support up to 2 processors. The ability to add another processor means that at some point in the future I can waste a bunch of money on even more excessive processing power. In the end I spent $400 for a Dell Precision T3600 with an E5-2660 and a 256GB SSD.&lt;/p&gt;

&lt;p&gt;In the near future I’ll be installing a &lt;a href=&#34;https://en.wikipedia.org/wiki/Hypervisor&#34;&gt;hypervisor&lt;/a&gt; and playing around with a bunch of virtual machines.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>