<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tinkering.xyz</title>
    <link>http://tinkering.xyz/index.xml</link>
    <description>Recent content on Tinkering.xyz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Mar 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://tinkering.xyz/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Using Python and SciPy to Minimize Total Interest Paid on Student Loans</title>
      <link>http://tinkering.xyz/posts/student-loan-simulator/</link>
      <pubDate>Thu, 09 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>http://tinkering.xyz/posts/student-loan-simulator/</guid>
      <description>

&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;First off, my wife and I live in the United States. I&amp;rsquo;m not sure how student loans work in other countries, so keep that in mind as I pretend to know what I&amp;rsquo;m talking about.&lt;/p&gt;

&lt;p&gt;My wife and I both have student loans (shocker). I&amp;rsquo;m still in graduate school, so I don&amp;rsquo;t have to start making payments on my student loans yet. On the other hand, my wife has a Grown Up job, so she has to make student loan payments. We&amp;rsquo;ve been incredibly fortunate to have some help paying our student loans, and that help has come in the form of a large check. The check isn&amp;rsquo;t large enough to pay off all of our loans at once, but it puts a significant dent in our total student loan debt.&lt;/p&gt;

&lt;p&gt;The question I wanted to answer was how to best distribute that check between the different loans that we have to reduce the total amount of interest that we&amp;rsquo;ll have paid once all of the loans are paid off.&lt;/p&gt;

&lt;h1 id=&#34;interest&#34;&gt;Interest&lt;/h1&gt;

&lt;p&gt;Before diving into the details, let&amp;rsquo;s talk about how interest is calculated for student loans. We have two different kinds of loans: subsidized and unsubsidized federal student loans.&lt;/p&gt;

&lt;h3 id=&#34;subsidized&#34;&gt;Subsidized&lt;/h3&gt;

&lt;p&gt;This is a pretty nice deal. The loan doesn&amp;rsquo;t accrue interest while you&amp;rsquo;re in school, while you&amp;rsquo;re in your grace period (typically six months after graduating), or while your loans are in deferrment (while I&amp;rsquo;m in graduate school).&lt;/p&gt;

&lt;h3 id=&#34;unsubsidized&#34;&gt;Unsubsidized&lt;/h3&gt;

&lt;p&gt;This type of loan is always accruing interest. What&amp;rsquo;s more is that any unpaid interest capitalizes (becomes part of the principal) at the end of your grace period. In other words, any interest that&amp;rsquo;s unpaid becomes part of the loan that you accrue interest on. This sucks because you&amp;rsquo;re effectively penalized for not making interest payments on your student loans while you&amp;rsquo;re in school.&lt;/p&gt;

&lt;h1 id=&#34;monthly-payments&#34;&gt;Monthly Payments&lt;/h1&gt;

&lt;p&gt;There is a ton of different student loan repayment plans. Some plans adjust your monthly payments based on your income, and others just payoff the loan in a specified number of years. In general, the longer it takes to payoff the loan, the more you pay in interest.&lt;/p&gt;

&lt;p&gt;For the sake of simplicity and minimizing the amount of interest I&amp;rsquo;ll pay over time I went with the standard repayment plan. The standard repayment plan has a term of 10 years, or 120 monthly payments. Monthly payments always target interest first, and what&amp;rsquo;s left over is applied to the principal.&lt;/p&gt;

&lt;p&gt;As part of this program I needed to calculate these monthly payments. Initially I thought you would calculate the monthly payment by dividing the principal up into 120 equal chunks plus accrued interest. Well, that&amp;rsquo;s not how things really work. In actuality, your monthly payments are constant, but over time you pay less towards interest and more towards the principal.&lt;/p&gt;

&lt;p&gt;I thought about how to derive the formula for the monthly payment for about 5 minutes, and then just looked for it on the internet. Most of the search results are just calculators that tell you what your payments are, but not how to calculate them, so I&amp;rsquo;m listing the formula here:&lt;/p&gt;

&lt;p&gt;M = (r * P) / (1 + (1 + r)^(-n))&lt;/p&gt;

&lt;p&gt;where &amp;ldquo;M&amp;rdquo; is the monthly payment, &amp;ldquo;r&amp;rdquo; is the monthly interest rate (yearly rate divided by 12, not as a percent), and &amp;ldquo;n&amp;rdquo; is the number of payments you have to make.&lt;/p&gt;

&lt;p&gt;The typical use case for this formula is calculating what your payments will be before you have to start paying them, but it also works if you have already made some payments. Just use your current principal for &amp;ldquo;P&amp;rdquo;, and your payments remaining for &amp;ldquo;n.&amp;rdquo;&lt;/p&gt;

&lt;h1 id=&#34;loan-details&#34;&gt;Loan Details&lt;/h1&gt;

&lt;p&gt;We have 7 loans, 4 for me, and 3 for my wife. My wife has been making student loan payments for a little while, but my payments won&amp;rsquo;t start for quite some time. One of my loans is subsidized, but all of the other loans are unsubsidized.&lt;/p&gt;

&lt;p&gt;The process of paying our loans will look like this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Make a big initial payment on some loans using the check we received&lt;/li&gt;
&lt;li&gt;Make payments on my wife&amp;rsquo;s loans for a while&lt;/li&gt;
&lt;li&gt;The interest on my loans will be added to their respective principals, their respective interests will be set back to zero, and we&amp;rsquo;ll have to start making payments on my loans&lt;/li&gt;
&lt;li&gt;Make payments on all of the loans until they&amp;rsquo;re paid off&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you read some personal finance blogs or student loan websites, you&amp;rsquo;ll generally get pretty good advice, but that advice tends to be pretty general. Some people say you should pay off the smallest loan first, then put the money you were spending on that loan towards the next smallest loan, and so on. This is called the &amp;ldquo;snowball&amp;rdquo; method. Other people say you should focus on the loan that costing you the most in interest. This is called the &amp;ldquo;avalanche&amp;rdquo; method.&lt;/p&gt;

&lt;p&gt;I was skeptical that any generally prescribed plan would work out best for us, so I got to work.&lt;/p&gt;

&lt;h1 id=&#34;the-program&#34;&gt;The Program&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;ve become more and more interested (get it?) in Go lately, but when I saw how much interest we were accruing each day, I decided that I would do this in Python just to knock it out as quickly as possible.&lt;/p&gt;

&lt;h3 id=&#34;loan-information&#34;&gt;Loan Information&lt;/h3&gt;

&lt;p&gt;I started out by making a class to hold all of the information related to each loan. For each loan, I need to have a name for the loan, the current principal, the current interest, the yearly interest rate as a percent, how many payments are left, how many months are left until payments start, and whether the loan accrues interest before payments start.&lt;/p&gt;

&lt;p&gt;From that information I came up with methods for making payments, accruing interest, keeping track of payments remaining and months until payments start, and keeping track of the total interest paid.&lt;/p&gt;

&lt;h3 id=&#34;payoff-algorithm&#34;&gt;Payoff Algorithm&lt;/h3&gt;

&lt;p&gt;The basic process is shown in the function below. I&amp;rsquo;ve ommitted a few small things here and there, but this is pretty close to what runs in my actual code. Note that my monthly budget is set to $1 million because everyone knows that graduate students are high rollers.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;payoff_loans&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(loans):&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;active_loans&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;active_loan_indices(loans)&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;monthly_budget&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;1000000.0&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;len(active_loans)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;:&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;make_payments(loans,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;active_loans,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;monthly_budget)&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;accrue_interest(loans)&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;increment_payoff_times(loans)&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;active_loans&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;active_loan_indices(loans)&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;return&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;for the last time
while something is true
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;payoff_loans&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(loans):&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;active_loans&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;active_loan_indices(loans)&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;monthly_budget&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;1000000.0&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;len(active_loans)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;:&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;make_payments(loans,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;active_loans,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;monthly_budget)&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;accrue_interest(loans)&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;increment_payoff_times(loans)&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;active_loans&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;active_loan_indices(loans)&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;return&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;someClass&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(object):&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;__init__&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(self):&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;self&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Behind the scenes, each loan object has a record of how many months are left until payments start, whether payments have started already, how many payments are left, etc. This information is used to determine when a given loan is active (payments are being made on it).&lt;/p&gt;

&lt;h3 id=&#34;optimization&#34;&gt;Optimization&lt;/h3&gt;

&lt;p&gt;For the optimization I used the &lt;code&gt;scipy.optimize.minimize&lt;/code&gt; function. The &lt;code&gt;minimize&lt;/code&gt; function requires a function to minimize and some parameters for the optimization procedure. I wanted to minimize the amount of interest I paid, so I wrote a function around the &lt;code&gt;payoff_loans&lt;/code&gt; function.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;minimization_func&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(loan_weights):&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;weight_sum&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;sum(loan_weights)&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;normalized_weights&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;[w&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;weight_sum&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;w&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;loan_weights]&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;initial_budget&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;1000000.0&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;initial_payments&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;[initial_budget&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;nw&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;nw&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;normalized_weights]&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;loans&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;make_loans()&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;payment,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;loan&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;zip(initial_payments,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;loans):&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;loan&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;make_payment(payment)&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;payoff_loans(loans)&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;total_paid_interest(loans)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The argument to this function is a list of weights. These weights are used to divide up the initial budget we have and make our initial payments. Each time a list of weights is supplied to &lt;code&gt;minimization_func&lt;/code&gt; initial payments for each loan are calculated, the program simulates the process of paying off the loans, and the total interest is calculated. The &lt;code&gt;minimize&lt;/code&gt; function goes through several iterations of coming up with weights, determining whether that made the total interest higher or lower, and making tweaks to the weights to see if it can do better.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Iterating with Long-Running Tasks</title>
      <link>http://tinkering.xyz/posts/iterating-with-long-tasks/</link>
      <pubDate>Mon, 20 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://tinkering.xyz/posts/iterating-with-long-tasks/</guid>
      <description>

&lt;h1 id=&#34;the-problem&#34;&gt;The Problem&lt;/h1&gt;

&lt;p&gt;One of the reasons that I bought a separate development machine was the friction surrounding tasks that take a long time to run on a Raspberry Pi. For a home automation related project I had to compile the &lt;code&gt;openzwave&lt;/code&gt; library on the Pi, and for another project in the works I had to compile &lt;code&gt;opencv&lt;/code&gt; on the Pi. Both of those tasks take hours to complete. Both projects were being built inside Docker containers, so modifying the Dockerfile to fix a bug would trigger a complete rebuild of the image. To make matters worse, I wasn&amp;rsquo;t saving the output of the build script to a file. Since I wasn&amp;rsquo;t logging the output of the build process, I had to have a persistent connection to the Pi (via &lt;code&gt;ssh&lt;/code&gt;) in order to see the error message if the build failed. In order to keep that connection open I had to prevent my Macbook Pro from sleeping, and press a button every now and then. If I had to go somewhere in the middle of a build, I would have to start that process all over again. Here&amp;rsquo;s what this process looks like in a nutshell.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Identify a bug&lt;/li&gt;
&lt;li&gt;Attempt to fix the bug by modifying the Dockerfile&lt;/li&gt;
&lt;li&gt;Start the build process&lt;/li&gt;
&lt;li&gt;Keep the &lt;code&gt;ssh&lt;/code&gt; connection open at all costs&lt;/li&gt;
&lt;li&gt;Wait a few hours for the build to fail&lt;/li&gt;
&lt;li&gt;If at any point the connection closes, go back to step 3&lt;/li&gt;
&lt;li&gt;Repeat until the build completes&lt;br /&gt;

&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Needless to say, this process is rage-inducing. Making incremental improvements takes forever, and is really demoralizing. Thankfully, there are some really basic solutions I&amp;rsquo;ve found to make life easier.&lt;/p&gt;

&lt;h1 id=&#34;solutions&#34;&gt;Solutions&lt;/h1&gt;

&lt;p&gt;The one thing that would make my sob story above less painful would have been the ability to view the output of the build script after the build completed, or to at least be able to see the build progress without the need for a persistent connection to the Pi. I&amp;rsquo;ve found two easy solutions to this that probably won&amp;rsquo;t be a surprise to anyone who programs for a living.&lt;/p&gt;

&lt;h3 id=&#34;using-tmux&#34;&gt;Using &lt;code&gt;tmux&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;tmux&lt;/code&gt; eliminates the need for a persistent connection to the Pi. In a nutshell, &lt;code&gt;tmux&lt;/code&gt; allows you to start a terminal session on the host machine that will continue to run regardless of whether you&amp;rsquo;re still connected to the machine. In other words, I can start the build process in a &lt;code&gt;tmux&lt;/code&gt; session, close the connection to the Pi, and the next time I open a connection to the Pi I&amp;rsquo;ll be able to see the current progress of the build in the &lt;code&gt;tmux&lt;/code&gt; session that&amp;rsquo;s still running.&lt;/p&gt;

&lt;p&gt;This is great if I want to see the progress of the build as it&amp;rsquo;s running, but it doesn&amp;rsquo;t solve the problem of being able to review the build log after the build fails.&lt;/p&gt;

&lt;h3 id=&#34;using-redirects&#34;&gt;Using Redirects&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;ve known about redirects for a while, but for some reason I never thought to use it to capture the output of the build.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;$ bash build.sh &amp;gt; build-log.txt
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The command above will redirect &lt;code&gt;stdout&lt;/code&gt; to &lt;code&gt;build-log.txt&lt;/code&gt;. If I want to capture errors as well, I need to redirect &lt;code&gt;stderr&lt;/code&gt; to &lt;code&gt;stdout&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;$ bash build.sh &lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;&amp;gt; build-log.txt &lt;span style=&#34;color: #ae81ff&#34;&gt;2&lt;/span&gt;&amp;gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In that command &lt;code&gt;1&lt;/code&gt; is the identifier for &lt;code&gt;stdout&lt;/code&gt;, &lt;code&gt;2&lt;/code&gt; is the identifier for &lt;code&gt;stderr&lt;/code&gt;, and &lt;code&gt;&amp;amp;1&lt;/code&gt; is the way that you reference a stream when you&amp;rsquo;re redirecting &lt;strong&gt;to&lt;/strong&gt; a stream. In short, the command tells &lt;code&gt;bash&lt;/code&gt; to run my script, redirect &lt;code&gt;stdout&lt;/code&gt; to a file, and redirect &lt;code&gt;stderr&lt;/code&gt; to whatever &lt;code&gt;stdout&lt;/code&gt; is pointed at (the same file as before).&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;I think the thing that I took away from this was that I needed to do a better job thinking about looking for standard solutions to my problems. If I run into a problem, there&amp;rsquo;s a very, very good chance that someone else out there has run into the same problem before. On the other hand, I already knew how to use redirects, so I just didn&amp;rsquo;t think hard enough about how to use the tools at my disposal.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Attempting an Unattended Ubuntu Installation</title>
      <link>http://tinkering.xyz/posts/unattended-ubuntu-install/</link>
      <pubDate>Sun, 19 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://tinkering.xyz/posts/unattended-ubuntu-install/</guid>
      <description>

&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;In a &lt;a href=&#34;http://tinkering.xyz/posts/development-hardware/&#34;&gt;recent post&lt;/a&gt; I mentioned that I bought a new development machine. The computer didn&amp;rsquo;t come with a graphics card or an operating system, which was fine with me since I was going to install Ubuntu Server on it anyway. I bought a cheap graphics card (~$25) to go with the computer, even though it would be a headless installation, since I would still need a way to connect the computer to a monitor if I wanted to tweak any BIOS settings. Well, I was dumb and bought a graphics card with a low-profile mounting bracket by accident when the computer needs a full-sized mounting bracket, so my graphics card doesn&amp;rsquo;t fit.&lt;/p&gt;

&lt;p&gt;After looking around for the mounting bracket online, it looks like my options are to buy the correct bracket on eBay from a seller in China, buy the same model graphics card with the correct bracket, or buy a new graphics card entirely. I decided that I wasn&amp;rsquo;t going to wait a month for the $7 bracket to arrive from China, so that option was out. From perusing Newegg, I found that I could get a substantially better graphics card for only a little bit more money, so I went that route. That card won&amp;rsquo;t get here for a few days, but I don&amp;rsquo;t want to wait that long to play with my new toy.&lt;/p&gt;

&lt;p&gt;During a typical Ubuntu installation process the installer asks you a few questions such as what to name the main user, what that user&amp;rsquo;s password should be, what timezone to use, etc, and will wait patiently until you provide answers. Since there&amp;rsquo;s no way for me connect a monitor to the computer at the moment, I have no way of seeing or responding to the installer&amp;rsquo;s questions. What I need is an installer that won&amp;rsquo;t stop and wait for me to answer its questions. This is called an &amp;ldquo;unattended install.&amp;rdquo;&lt;/p&gt;

&lt;h1 id=&#34;ubuntu-unattended-install-options&#34;&gt;Ubuntu Unattended Install Options&lt;/h1&gt;

&lt;p&gt;I found a few AskUbuntu posts (&lt;a href=&#34;http://askubuntu.com/questions/122505/how-do-i-create-a-completely-unattended-install-of-ubuntu&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://askubuntu.com/questions/806820/how-do-i-create-a-completely-unattended-install-of-ubuntu-desktop-16-04-1-lts&#34;&gt;here&lt;/a&gt;), but the processes detailed in those posts seemed hairier than I wanted to deal with, so I kept looking around. There&amp;rsquo;s also some &lt;a href=&#34;https://help.ubuntu.com/16.04/installation-guide/i386/ch04s06.html&#34;&gt;documentation&lt;/a&gt; from Canonical themselves about how to do this, but again this seemed more complicated than what I was looking for. At that point I was wondering whether a simple solution even existed, but eventually I stumbled onto &lt;a href=&#34;https://github.com/netson/ubuntu-unattended&#34;&gt;netson/ubuntu-unattended&lt;/a&gt;. This repository provides some scripts that will download the image for the Ubuntu Server image you want, ask you some questions, do some magic, and spit out an image that will do an unattended install. Hell. Yes.&lt;/p&gt;

&lt;h1 id=&#34;speed-bumps&#34;&gt;Speed Bumps&lt;/h1&gt;

&lt;h3 id=&#34;requires-ubuntu-debian-to-run&#34;&gt;Requires Ubuntu/Debian to Run&lt;/h3&gt;

&lt;p&gt;The first issue I ran into was that you need Ubuntu/Debian in order to run this. My main computer is a Macbook Pro, but luckily I have a Raspberry Pi 3 that my home automation server runs on (I&amp;rsquo;ll write about this at some point in the future). The Pi is running Raspbian, which is a version of Debian tweaked for the Raspberry Pi, so I lucked out there.&lt;/p&gt;

&lt;h3 id=&#34;timezones&#34;&gt;Timezones&lt;/h3&gt;

&lt;p&gt;I was a little confused about the format used for time zones. I see formats like &lt;code&gt;UTC&lt;/code&gt; and &lt;code&gt;EST&lt;/code&gt;, but I also see &lt;code&gt;America/New_York&lt;/code&gt;. I wasn&amp;rsquo;t sure which one was expected, so I just picked &lt;code&gt;EST&lt;/code&gt; and hoped for the best. Nothing has exploded yet, so I guess it worked.&lt;/p&gt;

&lt;h3 id=&#34;broken-download-link&#34;&gt;Broken Download Link&lt;/h3&gt;

&lt;p&gt;After asking you some questions the script will attempt to download the selected Ubuntu Server image. Well, the link in the script is broken, so you have to download the image manually (&lt;a href=&#34;http://old-releases.ubuntu.com/releases/xenial/ubuntu-16.04.1-server-amd64.iso&#34;&gt;link&lt;/a&gt;) and stick it in &lt;code&gt;/tmp/&lt;/code&gt;. The script was written such that Ubuntu Server 16.04.1 is the most recent version, so rather than messing with the script to figure out if it would work with the 16.04.2 (current at the time of writing), I just found the link for 16.04.1. I plan to install 16.04.1 and update to 16.04.2 immediately after the install.&lt;/p&gt;

&lt;h3 id=&#34;missing-isohybrid&#34;&gt;Missing &lt;code&gt;isohybrid&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;After downloading the image and putting it in the specified location, the script attempts to do its magic on the image that will let it run unattended. In my case, it gave me an error message saying that &lt;code&gt;isohybrid&lt;/code&gt; wasn&amp;rsquo;t found, but also told me that it finished. From the terminal output alone I&amp;rsquo;m not sure if that means it found a way around whatever problem it ran into, or if it &amp;ldquo;successfully&amp;rdquo; made an image that&amp;rsquo;s broken due to the missing dependency. Since this is supposed to run unattended, I&amp;rsquo;ll have no way of knowing if the installation fails until I boot from the image and let it do its thing. I&amp;rsquo;d rather know that the image is valid before trying to boot from it.&lt;/p&gt;

&lt;p&gt;I tried looking around to find the package that contains the &lt;code&gt;isohybrid&lt;/code&gt; command, and it looks like it&amp;rsquo;s supposed to be in the &lt;code&gt;syslinux-utils&lt;/code&gt; package. Well, &lt;code&gt;apt-cache search&lt;/code&gt; returned no results for &lt;code&gt;syslinux-utils&lt;/code&gt;, so I tried &lt;code&gt;syslinux&lt;/code&gt;, &lt;code&gt;syslinux-common&lt;/code&gt;, &lt;code&gt;isolinux&lt;/code&gt;, and &lt;code&gt;xorriso&lt;/code&gt;, but none of them worked. From what I can tell, there&amp;rsquo;s just not an &lt;code&gt;isohybrid&lt;/code&gt; package for &lt;code&gt;armhf&lt;/code&gt; (Raspberry Pi), so that put the nail in the coffin of this idea. You can download the source for the &lt;code&gt;syslinux&lt;/code&gt; package, but compiling anything from source on a Pi is glacially slow, so I decided against that. You could probably do it in a pinch, but I didn&amp;rsquo;t have the patience for it.&lt;/p&gt;

&lt;h1 id=&#34;what-i-ended-up-doing&#34;&gt;What I Ended Up Doing&lt;/h1&gt;

&lt;p&gt;In the end, I made a bootable USB with the Ubuntu Server installer on it and plugged the SSD from my development machine into my Windows desktop machine. From there I did the typical installation process, and then put the SSD back into my development machine. By the time I string up another ethernet cable across the ceiling of my apartment to connect my development machine to my router, my graphics card will probably be here. I ended spending about a day doing this, and I could have spent a lot less time if I just waited for the graphics card, but quick and painless just isn&amp;rsquo;t the Tinkering way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How Hyperthreading Works ... I Think</title>
      <link>http://tinkering.xyz/posts/hyperthreading/</link>
      <pubDate>Fri, 17 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://tinkering.xyz/posts/hyperthreading/</guid>
      <description>&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt; - A hyperthreading-enabled processor reports to the operating system that it is actually two separate processors so that the CPU assumes the responsibility of deciding when it should schedule work to be done on multiple jobs running at the same time. The CPU is much more efficient than the operating system at this decision making process, which allows it to better manage its time and resources. In some cases this results in doubled performance, but in others it doesn’t increase performance at all. The type of work being done by the processor is a large deciding factor in whether hyperthreading increases performance.&lt;/p&gt;

&lt;p&gt;In my last post I talked about buying a development machine. Since I&amp;rsquo;ll be doing a lot of compiling on this machine the particular CPU installed was one of the details I focused on most. Some of the available processors offered what Intel calls &amp;ldquo;Hyperthreading&amp;rdquo; (HT). This is something that Intel still uses today. In broad strokes, Intel&amp;rsquo;s desktop processor lineup looks like this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;i3 - 2 cores with HT&lt;/li&gt;
&lt;li&gt;i5 - 4 cores without HT&lt;/li&gt;
&lt;li&gt;i7 - 4 or more cores with HT&lt;br /&gt;

&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While doing some research on this topic I found an &lt;a href=&#34;http://www.sheepguardingllama.com/2008/03/cpus-cores-and-threads-how-many-processors-do-i-have/&#34;&gt;article&lt;/a&gt; that clarifies the distinction between a CPU, a processor, and a core. The article is nearly 10 years old at this point, but I learned a few things and found it to still be relevant.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s get back to the discussion of HT. A processor with &lt;code&gt;N&lt;/code&gt; physical processor cores supports &lt;code&gt;N&lt;/code&gt; threads without HT, or &lt;code&gt;2N&lt;/code&gt; threads with HT. A CPU &lt;a href=&#34;https://arstechnica.com/business/2011/04/ask-ars-what-is-a-cpu-thread/&#34;&gt;thread&lt;/a&gt; is basically a pipeline of instructions that are fed to the CPU.  Intel&amp;rsquo;s &lt;a href=&#34;https://ark.intel.com/m/products/65719/Intel-Core-i7-3770-Processor-8M-Cache-up-to-3_90-GHz&#34;&gt;product pages&lt;/a&gt; are pretty informative, and report the number of threads supported by a given processor. In some places I&amp;rsquo;ve seen threads called &amp;ldquo;logical cores&amp;rdquo; or “logical processors.” In that case a CPU without HT has the same number of logical and physical processor cores, but a CPU that supports HT has twice as many logical cores as physical cores.&lt;/p&gt;

&lt;p&gt;Let’s tie this back to my original question about code compilation. GNU &lt;code&gt;make&lt;/code&gt; allows you to pass it an argument telling it how many parallel jobs to spawn. For example, the following code would allow 4 different jobs to run in parallel during compilation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;$ make -j4
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The documentation for &lt;code&gt;make&lt;/code&gt; tells you to set the argument of the &lt;code&gt;-j&lt;/code&gt; flag to the number of processors. The question then becomes whether &amp;ldquo;processor&amp;rdquo; means physical processor cores or logical processors (CPU threads).&lt;/p&gt;

&lt;p&gt;It turns out I&amp;rsquo;m not the first person to ask this question (go figure). In &lt;a href=&#34;http://stackoverflow.com/questions/2499070/gnu-make-should-the-number-of-jobs-equal-the-number-of-cpu-cores-in-a-system&#34;&gt;this&lt;/a&gt; Stack Overflow post someone asks basically the same question. One of the responders posts compilation times done on a 4-core processor with HT and a variety of parallel job counts.  Before reading about what HT actually is or how it works, I assumed that a CPU that supported HT would be able to do twice as much work as a non-HT CPU since the HT CPU supported two execution threads per physical processor as opposed to a single execution thread per processor in a non-HT CPU. That assumption turns out not to be true.&lt;/p&gt;

&lt;p&gt;Looking at the compilation times in that SO post, there is a big difference in compilation time going from 1-4 jobs (148s vs 59s), a very small difference from 4-8 jobs (59s vs 54s), and basically no difference with more than 8 jobs.&lt;/p&gt;

&lt;p&gt;Regardless of HT, it makes sense that you would see a big speed up going from 1 to 4 jobs since at the very least you have 4 physical processors available to work independently. On the other hand, if the number of execution threads is the bottleneck then you would expect a much bigger speed up than what the poster reported going from 4 to 8 jobs. To understand the discrepancy we have to dig in to the details of how a processor works. I&amp;rsquo;m by no means an expert on this topic, so I&amp;rsquo;m sure that I&amp;rsquo;m glossing over very important details, but I&amp;rsquo;ve tried to explain the following in an accessible way.&lt;/p&gt;

&lt;p&gt;Everything related to feeding instructions to a processor is highly optimized to prevent the processor from having to wait around for instructions. If we think about feeding instructions to the processor through a pipeline, the processor gets the most done when that pipeline is full and the instructions are related to the same thing. The operating system (OS) sees that there is a job that needs to be done, and passes the relevant instructions through the pipeline to the processor.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s complicate matters by saying that there are two jobs that need to be done and they have equal priorities. In the case of a single processor without HT, the OS flips back and forth between telling the processor to work on job 1 and job 2, and each time it does so the processor has to change gears. Clearly this is not the most efficient use of the processor&amp;rsquo;s time, and letting the OS tie itself up trying to figure out which of the two jobs to tell the processor to work on probably isn&amp;rsquo;t doing us any favors.&lt;/p&gt;

&lt;p&gt;Enter hyperthreading. According to &lt;a href=&#34;https://www.percona.com/blog/2015/01/15/hyper-threading-double-cpu-throughput/&#34;&gt;this article&lt;/a&gt;, a processor with HT assumes the responsibility of deciding when to work on which job by essentially faking out the OS. A processor with HT has two instruction pipelines per processor, rather than one, and it fakes out the OS by telling it that each instruction pipeline is a separate processor. Now when the OS has two jobs of equal priority it doesn&amp;rsquo;t have to think about when to work on one or the other, it just hands one job to one &amp;ldquo;processor&amp;rdquo; and the other job to the other &amp;ldquo;processor&amp;rdquo; and lets them get on with it.&lt;/p&gt;

&lt;p&gt;At this point you might be wondering what that accomplishes. Both with or without HT something is deciding when the processor should work on job 1 or job 2. In one case it&amp;rsquo;s the OS, and in the other case it&amp;rsquo;s the processor. The answer lies in the fact that everything gets faster as you get closer to the CPU. Letting the CPU decide which of its instruction pipelines to churn through is much more efficient than letting the OS call the shots. Think of it as walking down to your manager&amp;rsquo;s office to ask a question as opposed to trying to get a meeting with the CEO.&lt;/p&gt;

&lt;p&gt;Now we can tie this back to our code compilation and the reason that you sometimes only see a modest speed improvement with HT. A processor with HT doesn&amp;rsquo;t behave like two complete, separate processors. True, there are two separate pipelines of instructions for the CPU, but you still only have a single CPU and you&amp;rsquo;re limited by how fast it process a single instruction. Compared to a processor without HT, a processor with HT is better at managing its time and resources, but at the end of the day it&amp;rsquo;s still just a single processor.&lt;/p&gt;

&lt;p&gt;However, one thing I’ve completely ignored up to this point is the type of work the CPU is doing. Some work is well-suited to being parallelized, whereas other work doesn’t see any benefit. It seems to me that the most important aspect of this is where the bottleneck lies. &lt;a href=&#34;http://superuser.com/a/279803&#34;&gt;This&lt;/a&gt; SO post discusses this bottleneck effect. The poster runs a variety of algorithms on a HT-enabled CPU, and reports the speedup as a function of the number of threads. For two of the algorithms you see a linear increase all the way up to the maximum number of threads, whereas two other algorithms top out at the number of physical processors. The algorithms that scale with the number of threads are bottlenecked by something other than the processor, which means that the processor can work on one job while the other job is waiting for whatever external resources are causing the bottleneck. The other two algorithms are limited strictly by the CPU, so the ability to put one job on hold while working on the other doesn&amp;rsquo;t provide any benefits.&lt;/p&gt;

&lt;p&gt;One thing to keep in mind with that post is that it reports the speedup relative to a single thread running the same algorithm. In other words, it doesn’t tell you anything about whether one algorithm is faster than another on a single thread, or whether HT makes one algorithm faster than another.&lt;/p&gt;

&lt;p&gt;To wrap up, a hyperthreading-enabled processor reports that it is actually two separate processors to the operating system so that the CPU assumes the responsibility of deciding when it should schedule work to be done on multiple jobs running at the same time. The CPU is much more efficient than the operating system at this decision making process, which allows it to better manage its time and resources. In some cases this results in doubled performance, but in others it doesn’t increase performance at all. The type of work being done by the processor is a large deciding factor in whether hyperthreading increases performance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Development Hardware for a Steal</title>
      <link>http://tinkering.xyz/posts/development-hardware/</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://tinkering.xyz/posts/development-hardware/</guid>
      <description>

&lt;p&gt;Yes, this is posted on Valentine&amp;rsquo;s Day, but my wife is out of town so I have nothing better to do.&lt;/p&gt;

&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;I do all of my programming on my Macbook Pro, but which hardware the code runs on varies. I have a Raspberry Pi 3, a desktop running Windows that’s attached to a Drobo, and my Macbook Pro. Windows isn&amp;rsquo;t *nix based and has no built-in package manager (neither does macOS, but at least it&amp;rsquo;s Unix based), so there&amp;rsquo;s more friction than I would like with regards to programming on Windows. Most of the programming I’ve done for the Pi has involved developing Docker containers with dependencies that must be built from source. This is rage inducing for a number of reasons:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Compiling anything from source on a Pi is glacially slow.&lt;/li&gt;
&lt;li&gt;I connect to the Pi via &lt;code&gt;ssh&lt;/code&gt;, which means that I don’t see any error messages if the connection is interrupted while Docker is building an image.&lt;/li&gt;
&lt;li&gt;I haven’t found a way to have Docker save the output of the build process so that I can look at it later.&lt;br /&gt;

&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of that is to say that I have to be connected to the Pi throughout the entire multi-hour long build process if I want to see the error message at the end. What if I start the build process at work and need to go home while it’s still building? I decided that I wanted to spend more time programming and less time &lt;a href=&#34;https://en.wiktionary.org/wiki/yak_shaving&#34;&gt;yak shaving&lt;/a&gt;, so I started looking at what kind of computer I could get for what kind of money.&lt;/p&gt;

&lt;h1 id=&#34;the-search&#34;&gt;The Search&lt;/h1&gt;

&lt;p&gt;The first thing I did was pick a bunch of new parts on Newegg and see how much it came out to. For a Skylake i5 processor, some DDR4 RAM, a small SSD, and some mini-ITX parts the build came out to about $500. I didn’t want to spend that much on a computer that would only be marginally faster than my current desktop, so I started looking around on eBay.&lt;/p&gt;

&lt;p&gt;I eventually discovered that you can buy used servers on eBay for $200-$300. When you consider that the available servers typically come with two processors, each of which is either 4-core or 6-core, and somewhere in the range of 16GB-48GB of RAM, an old server becomes a pretty enticing option with regards to bang for your buck.&lt;/p&gt;

&lt;p&gt;The first thing I realized while browsing used servers on eBay was that I had no idea what I was looking at. I, like lots of other nerds, have built my own desktop from scratch, but that did basically nothing to educate me about server hardware. After poking around on the internet for a little while I found &lt;a href=&#34;https://www.reddit.com/r/homelab/&#34;&gt;/r/homelab&lt;/a&gt;, which is a subreddit for people who want to build their own quasi-enterprise-level computer lab at home. The wiki there has a bunch of information about which servers to buy, which to avoid, etc. More importantly, it provides a warning about the downsides of these servers.&lt;/p&gt;

&lt;p&gt;Most of these servers are several years old, so their processors haven’t reaped benefits from recent advancements in power efficiency. These servers were also designed to keep their internals cool in an environment where you have lots of heat-producing hardware running at full-bore while stuffed in a small box next to a bunch of other small boxes that are also spewing heat. Needless to say, you need a lot of beefy fans to keep things cool in that kind of environment. This means that some servers sound like small jets taking off. Another issue is that the hard drives used in servers are typically not the same hard drives that you would find in a desktop computer. Server hard drives use &lt;a href=&#34;https://en.wikipedia.org/wiki/Serial_Attached_SCSI&#34;&gt;SAS&lt;/a&gt; rather than &lt;a href=&#34;https://en.wikipedia.org/wiki/Serial_ATA&#34;&gt;SATA&lt;/a&gt;, and typically spin at 10k-15k RPM compared to 5.4k-7.2k like consumer hard drives. The read/write speed of a hard drive increases with the rate at which the disk spins, but the power consumption increases as well.&lt;/p&gt;

&lt;p&gt;On top of that, some of the processors that you&amp;rsquo;ll find in these servers don&amp;rsquo;t have support for Intel&amp;rsquo;s AES-NI instructions (see &lt;a href=&#34;https://en.wikipedia.org/wiki/AES_instruction_set&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://crypto.stackexchange.com/questions/19544/how-exactly-does-aes-ni-work&#34;&gt;here&lt;/a&gt;), which provide hardware acceleration for certain encryption related tasks. Just to be clear, you can still do encryption related tasks with processors that don&amp;rsquo;t support the AES-NI instruction set, it will just be much faster on processors that &lt;strong&gt;do&lt;/strong&gt; support the AES-NI instruction set.&lt;/p&gt;

&lt;p&gt;Put all of that together and you have older, less efficient processors, a bunch of loud fans running at full speed all the time, and a bunch of hard drives that consume more power than your average consumer hard drive. The power consumption of a server like this can be anywhere from 140W-175W &lt;strong&gt;at idle&lt;/strong&gt;, but as high as 250W at full load. I did a quick calculation based on the cost of electricity from my last electric bill, and a server consuming 140W at idle would cost about $15/month in electricity alone. That’s $180/year, which is a considerable fraction of the cost of the server itself. With that in mind, I decided to see what else I could get for a similar amount of money.&lt;/p&gt;

&lt;h1 id=&#34;what-i-bought&#34;&gt;What I Bought&lt;/h1&gt;

&lt;p&gt;I eventually found some workstations built around Xeon E5-2660/E5-2670 processors, which are slightly newer 8-core server processors with performance only slightly lower than that of the fastest servers that I was looking at before. The workstations only come with 1 processor, but the motherboards support up to 2 processors. The ability to add another processor means that at some point in the future I can waste a bunch of money on even more excessive processing power. In the end I spent $400 for a Dell Precision T3600 with an E5-2660 and a 256GB SSD.&lt;/p&gt;

&lt;p&gt;In the near future I’ll be installing a &lt;a href=&#34;https://en.wikipedia.org/wiki/Hypervisor&#34;&gt;hypervisor&lt;/a&gt; and playing around with a bunch of virtual machines.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>