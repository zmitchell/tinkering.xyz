<!DOCTYPE html>
<html lang="en">
  
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <title>Optimization story - quantum mechanics simulation speedup &middot; Tinkering</title>
    <meta name="description" content="Come for the Foo, stay for the Bar" />
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#aa0000">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <link rel="alternate" type="application/atom+xml" title="RSS" href="https://tinkering.xyz/atom.xml">

    <style>html,body{background:#fffaf7;color:#2d2d2d;font:18px/1.5 -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol"}a,a:visited{color:darkred;text-decoration:none}a:hover{text-decoration:underline}main{margin:auto;max-width:65ch;padding:0.8rem}pre{background:white;overflow:scroll;padding:1rem}td{border:1px solid #2d2d2d;padding:10px}img{height:auto;max-width:100%}.homepage-list{list-style:none;padding:1rem 0}.homepage-list li{align-items:center;display:flex;flex-wrap:wrap;justify-content:space-between;margin-bottom:10px}@media (max-width: 65ch){.homepage-list li a{width:100%}}code{font-size:90%}p>code,li>code{padding:.15em .25em;color:#bf616a;background-color:#e8e8e8;border-radius:3px}
</style>

    <meta property="og:site_name" content="Tinkering">
      <meta name="author" content="Zach Mitchell" />
      <meta property="og:title" content="Optimization story - quantum mechanics simulation speedup">
      <meta property="og:description" content="">
      <meta property="og:url" content="https://tinkering.xyz/fmo-optimization-story/">
      <meta property="og:image" content="">

      <meta property="og:type" content="article" />
        <meta property="article:published_time" content="2022-01-09T00:00:00+00:00" />

      <link rel="prev" href="https://tinkering.xyz/lazy-grad-student/" />
      <link rel="next" href="https://tinkering.xyz/bit-mask-tables/" />
    

  </head>
  

  <body>
    <main id="main" role="main">

      
      <header role="banner">
        <h3 style="margin-top:0;">
          <a href="https://tinkering.xyz" title="Home">Tinkering</a>
          <br /><small>Come for the Foo, stay for the Bar</small>
        </h3>
      </header>
      <hr />
      

      
<article>
  <h1>Optimization story - quantum mechanics simulation speedup</h1>

  
  <p style="font-size:90%;">Posted on <time datetime=" 2022-01-09T00:00:00+00:00">January 09, 2022</time></p>
  

  
  <div style="font-size:90%;">
    <p>Table of Contents:</p>
    <ul>
      
      <li>
        <a href="https://tinkering.xyz/fmo-optimization-story/#problem-description">Problem description</a>
        
      </li>
      
      <li>
        <a href="https://tinkering.xyz/fmo-optimization-story/#finding-the-bottleneck">Finding the bottleneck</a>
        
      </li>
      
      <li>
        <a href="https://tinkering.xyz/fmo-optimization-story/#optimizing-cd">Optimizing CD</a>
        
        <ul>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#avoiding-superfluous-lookups">Avoiding superfluous lookups</a>
          </li>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#skipping-half-of-the-calculations">Skipping half of the calculations</a>
          </li>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#skipping-the-diagonal">Skipping the diagonal</a>
          </li>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#caching-some-computations">Caching some computations</a>
          </li>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#letting-numpy-take-control">Letting NumPy take control</a>
          </li>
          
        </ul>
        
      </li>
      
      <li>
        <a href="https://tinkering.xyz/fmo-optimization-story/#calling-lapack-routines-directly">Calling LAPACK routines directly</a>
        
      </li>
      
      <li>
        <a href="https://tinkering.xyz/fmo-optimization-story/#rust-rewrite">Rust rewrite</a>
        
      </li>
      
      <li>
        <a href="https://tinkering.xyz/fmo-optimization-story/#matching-outputs">Matching outputs</a>
        
      </li>
      
      <li>
        <a href="https://tinkering.xyz/fmo-optimization-story/#broadened-spectra">Broadened spectra</a>
        
        <ul>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#making-it-parallel">Making it parallel</a>
          </li>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#doing-less-work">Doing less work</a>
          </li>
          
        </ul>
        
      </li>
      
      <li>
        <a href="https://tinkering.xyz/fmo-optimization-story/#final-attempts">Final attempts</a>
        
        <ul>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#looking-at-the-assembly">Looking at the assembly</a>
          </li>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#instruction-level-parallelism">Instruction level parallelism</a>
          </li>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#explicit-simd">Explicit SIMD</a>
          </li>
          
          <li>
            <a href="https://tinkering.xyz/fmo-optimization-story/#cachegrind">Cachegrind</a>
          </li>
          
        </ul>
        
      </li>
      
      <li>
        <a href="https://tinkering.xyz/fmo-optimization-story/#wrapping-up">Wrapping up</a>
        
      </li>
      
    </ul>
  </div>
  

  <hr />
<details>
    <summary>Click here for tl;dr and spoilers</summary>
    <p>I wanted to make a physics simulation 100x faster. I got it 4x faster exercising my best NumPy skills, and 50x faster after rewriting in Rust with a couple of other optimizations. After getting a machine with more (and faster) cores this jumped to 250x.</p>

</details>
<hr />
<p>As part of my research I've been modeling absorption spectra from first principles i.e. computing how much light a protein absorbs at a given wavelength based on the locations and charges of all the atoms in the protein. Luckily, the vast majority of this work is done by collaborators running simulations on supercomputers. That process goes like this:</p>
<ul>
<li>Grab the structure of the protein (the precise location of all of the atoms in the protein) from the <a href="https://www.rcsb.org">Protein Database</a>. People spend entire careers trying to obtain these structures. I'm studying the <a href="https://en.wikipedia.org/wiki/Fenna%E2%80%93Matthews%E2%80%93Olson_complex">Fenna-Matthews-Olson (FMO) complex</a>.</li>
<li>Put the protein in a box and fill the remaining space with water molecules.</li>
<li>Calculate the forces between the atoms to predict where they'll move in the next time step. Apply some clever optimizations so that the simulation completes before the heat death of the universe.</li>
<li>The protein structure you grabbed from the database may not be the exact structure as you'd find in nature, so let the protein jiggle around like this for a while until the atoms in the protein find equilibrium positions to jiggle around.</li>
<li>Save snapshots of the protein structure during this equilibrium-jiggling for post-processing.</li>
</ul>
<p>There's a variety of information you can extract from these snapshots, but the parts that are important to me are:</p>
<ul>
<li>A <a href="https://en.wikipedia.org/wiki/Hamiltonian_(quantum_mechanics)">Hamiltonian</a>, which is a matrix representing a quantum-mechanical description of the system and the interactions between parts of the system</li>
<li><a href="https://en.wikipedia.org/wiki/Transition_dipole_moment">Transition dipole moments</a> of certain molecules</li>
<li>Positions of certain molecules</li>
</ul>
<p>From this information I can calculate the <a href="https://simple.wikipedia.org/wiki/Absorption_spectroscopy">absorption spectrum</a> (how much light is absorbed at each wavelength) and the <a href="https://en.wikipedia.org/wiki/Circular_dichroism">circular dichroism (CD) spectrum</a>. Once I have these spectra I compare them against experimentally measured spectra to see how accurate our modeling techniques are. Sometimes it works well:</p>
<p><img src="/images/sim_spectra.png" alt="Comparison of simulated and experimental spectra" /></p>
<p>As is common in physics, part of this research entails figuring out how many details we can safely ignore. Reducing the FMO complex to an 8x8 matrix already throws away a huge number of details, namely the effect of molecular vibrations and vibrations of the entire protein, but they happen to be details that we can't calculate in a reasonable amount of time. An exact calculation would require diagonalizing a 1,000,000x1,000,000 matrix. That's an 8TB matrix (assuming 64-bit floats), and it's not a sparse one either.</p>
<p>Woof.</p>
<p>This brings us to my current task. I know that some simulations and experimental spectra don't match perfectly, so I wondered if I could fit small tweaks to the Hamiltonian (among other things) in order to get them to match. If those tweaks are within the modeling error of the simulations, that's great and it means we're on the right track. If not, it means we're leaving out important details.</p>
<p>Here's the problem: some fits take 8 hours to complete on my 2-core laptop. That's a hell of a feedback cycle time! The goal is to run the simulations (locally) in about 5 minutes (~100x speedup) without doing anything too crazy. We've found our rabbit hole, let's dive in!</p>
<h2 id="problem-description">Problem description</h2>
<p>First let's describe the shape of my data. A complete configuration consists of:</p>
<ul>
<li>A Hamiltonian (8x8 array)</li>
<li>The transition dipole moments (8x3 array, one row per molecule, one column each for x-, y-, and z-coordinates)</li>
<li>The positions (same layout as the dipole moments).</li>
</ul>
<p>The number of configurations used to compute the spectrum can vary. Empirically determined configurations have been published and consist of a single configuration each. The simulations our collaborators are doing produce a single configuration per snapshot, and in this case I've been supplied with 100 snapshots.</p>
<p>In order to calculate the absorption spectrum I first need to compute the <a href="https://simple.wikipedia.org/wiki/Eigenvalues_and_eigenvectors">eigenvalues and eigenvectors</a> of the Hamiltonian (this is also called <a href="https://en.wikipedia.org/wiki/Diagonalizable_matrix#Diagonalization">diagonalization</a> of the Hamiltonian).</p>
<p>Those eigenvectors are used to compute <em>new</em> transition dipole moments that are weighted sums of the original dipole moments (the eigenvectors are essentially 1D arrays containing the weights). These are called &quot;excitonic&quot; transition dipole moments.</p>
<p>From these excitonic transition dipole moments I calculate the &quot;stick spectrum&quot; for absorption and CD. We call this a stick spectrum because it just tells you the location and magnitude (and sign, in the case of CD) of each peak in the spectrum rather than the smooth continuous curve you would normally associate with a spectrum.</p>
<p>From this stick spectrum we compute a &quot;broadened&quot; spectrum by placing a Gaussian (smooth bell curve) on top of each stick in the stick spectrum. The number of points in a broadened spectrum (the resolution) is user configurable, but in practice each one ends up being about 1500 points. If I have a single configuration, I'm done. If I have multiple configurations, I do this for each one and average them. I want to minimize the error between the computed and experimental spectra.</p>
<p>It's also worth going over my naming conventions. From looking at my code you'll see <code>ham</code> and <code>pigs</code> everywhere, and you may conclude from that that I have an unhealthy obsession with pork. This isn't true, in fact I'm a vegetarian. In reality <code>ham</code> is short for &quot;Hamiltonian&quot;, and <code>pigs</code> is short for &quot;pigments&quot;. A pigment is a light absorbing molecule (like a chlorophyll). Additionally, the mathematical symbol for a dipole moment is the Greek letter &quot;mu&quot;, so <code>mus</code> is the array of dipole moments. The letter <code>r</code> is used to denote position, so <code>rs</code> is an array of positions. The snapshot files containing the Hamiltonian, dipole moments, and positions are named <code>conf*.csv</code>, so I call this collection of information a <code>conf</code>.</p>
<p>The code I use to run these simulations can be found here: <a href="https://github.com/savikhin-lab/fmo_analysis">savikhin-lab/fmo_analysis</a>.</p>
<h2 id="finding-the-bottleneck">Finding the bottleneck</h2>
<p>The first step in optimization is measuring to find out which part is slow. Computing spectra for multiple confs just computes individual spectra in a loop, so I decided to profile a fit of a single conf.</p>
<p>When it comes to Python one of my go-to tools is <a href="https://github.com/benfred/py-spy">py-spy</a>, a sampling profiler for Python. I ran <code>py-spy</code> on my <code>fit_shifts.py</code> script and this what it looked like:
<img src="/images/fmo_analysis_fitting_single_flamegraph.svg" alt="flamegraph of the fitting program" /></p>
<p>This is the important part:</p>
<ul>
<li>87.5% <code>make_stick_spectrum</code></li>
<li>10% <code>make_broadened_spectrum</code></li>
</ul>
<p>The takeaway here is that <code>make_stick_spectrum</code> dominates the execution time. Note that this is <em>after</em> I made some optimizations several weeks ago, so imagine how much more skewed towards <code>make_stick_spectrum</code> it would be if I had done this back then!</p>
<hr />
<details>
    <summary>Aside: NumPy isn't always fast!</summary>
    <p>It turns out that NumPy's cross product function <code>np.cross</code> is very slow for small arrays, 10x slower than computing it manually:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>m1 = np.</span><span style="color:#bf616a;">array</span><span>([</span><span style="color:#d08770;">1.</span><span>, </span><span style="color:#d08770;">0.</span><span>, </span><span style="color:#d08770;">0.</span><span>])
</span><span>m2 = np.</span><span style="color:#bf616a;">array</span><span>([</span><span style="color:#d08770;">0.</span><span>, </span><span style="color:#d08770;">1.</span><span>, </span><span style="color:#d08770;">0.</span><span>])
</span><span style="color:#65737e;"># Built in, 39us
</span><span>cross = np.</span><span style="color:#bf616a;">cross</span><span>(m1, m2)
</span><span style="color:#65737e;"># Manually, 3.9us
</span><span>mu_cross = np.</span><span style="color:#bf616a;">empty</span><span>(</span><span style="color:#d08770;">3</span><span>)
</span><span>mu_cross[</span><span style="color:#d08770;">0</span><span>] = m1[</span><span style="color:#d08770;">1</span><span>] * m2[</span><span style="color:#d08770;">2</span><span>] - m1[</span><span style="color:#d08770;">2</span><span>] * m2[</span><span style="color:#d08770;">1</span><span>]
</span><span>mu_cross[</span><span style="color:#d08770;">1</span><span>] = m1[</span><span style="color:#d08770;">2</span><span>] * m2[</span><span style="color:#d08770;">0</span><span>] - m1[</span><span style="color:#d08770;">0</span><span>] * m2[</span><span style="color:#d08770;">2</span><span>]
</span><span>mu_cross[</span><span style="color:#d08770;">2</span><span>] = m1[</span><span style="color:#d08770;">0</span><span>] * m2[</span><span style="color:#d08770;">1</span><span>] - m1[</span><span style="color:#d08770;">1</span><span>] * m2[</span><span style="color:#d08770;">0</span><span>] 
</span></code></pre>
<p>This isn't a knock against NumPy. NumPy tries to work well for a wide variety of cases, provide a consistent API, provide nice error messages, etc and it generally succeeds. However, the tradeoff for all of that nice functionality appears to be significant overhead in some cases. You may be able to squeeze out some extra performance by stripping out the pieces you don't need. Another area I've done this is <code>np.savetxt</code> because I always know the data I'm going to save will be a certain shape.</p>

</details>
<hr />
<p>This is what <code>make_stick_spectrum</code> looks like:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">make_stick_spectrum</span><span>(</span><span style="color:#bf616a;">config</span><span>: Config, </span><span style="color:#bf616a;">ham</span><span>: np.ndarray, </span><span style="color:#bf616a;">pigs</span><span>: List[Pigment]) -&gt; Dict:
</span><span>    </span><span style="color:#65737e;">&quot;&quot;&quot;Computes the stick spectra and eigenvalues/eigenvectors for the system.&quot;&quot;&quot;
</span><span>    ham, pigs = </span><span style="color:#bf616a;">delete_pigment</span><span>(config, ham, pigs)
</span><span>    n_pigs = ham.shape[</span><span style="color:#d08770;">0</span><span>]
</span><span>    </span><span style="color:#b48ead;">if </span><span>config.delete_pig &gt; n_pigs:
</span><span>        </span><span style="color:#b48ead;">raise </span><span style="color:#bf616a;">ValueError</span><span>(</span><span style="color:#b48ead;">f</span><span>&quot;</span><span style="color:#a3be8c;">Tried to delete pigment </span><span>{config.delete_pig}</span><span style="color:#a3be8c;"> but system only has </span><span>{n_pigs}</span><span style="color:#a3be8c;"> pigments.</span><span>&quot;)
</span><span>    e_vals, e_vecs = np.linalg.</span><span style="color:#bf616a;">eig</span><span>(ham)
</span><span>    pig_mus = np.</span><span style="color:#bf616a;">zeros</span><span>((n_pigs, </span><span style="color:#d08770;">3</span><span>))
</span><span>    </span><span style="color:#b48ead;">if </span><span>config.normalize:
</span><span>        total_dpm = np.</span><span style="color:#bf616a;">sum</span><span>([np.</span><span style="color:#bf616a;">dot</span><span>(p.mu, p.mu) </span><span style="color:#b48ead;">for </span><span>p </span><span style="color:#b48ead;">in </span><span>pigs])
</span><span>        </span><span style="color:#b48ead;">for </span><span>i </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(</span><span style="color:#96b5b4;">len</span><span>(pigs)):
</span><span>            pigs[i].mu /= total_dpm
</span><span>    </span><span style="color:#b48ead;">for </span><span>i, p </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">enumerate</span><span>(pigs):
</span><span>        pig_mus[i, :] = pigs[i].mu
</span><span>    exciton_mus = np.</span><span style="color:#bf616a;">zeros_like</span><span>(pig_mus)
</span><span>    stick_abs = np.</span><span style="color:#bf616a;">zeros</span><span>(n_pigs)
</span><span>    stick_cd = np.</span><span style="color:#bf616a;">zeros</span><span>(n_pigs)
</span><span>    </span><span style="color:#b48ead;">for </span><span>i </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n_pigs):
</span><span>        exciton_mus[i, :] = np.</span><span style="color:#bf616a;">sum</span><span>(np.</span><span style="color:#bf616a;">repeat</span><span>(e_vecs[:, i], </span><span style="color:#d08770;">3</span><span>).</span><span style="color:#bf616a;">reshape</span><span>((n_pigs, </span><span style="color:#d08770;">3</span><span>)) * pig_mus, </span><span style="color:#bf616a;">axis</span><span>=</span><span style="color:#d08770;">0</span><span>)
</span><span>        stick_abs[i] = np.</span><span style="color:#bf616a;">dot</span><span>(exciton_mus[i], exciton_mus[i])
</span><span>        energy = e_vals[i]
</span><span>        </span><span style="color:#b48ead;">if </span><span>energy == </span><span style="color:#d08770;">0</span><span>:
</span><span>            </span><span style="color:#65737e;"># If the energy is zero, the pigment has been deleted
</span><span>            </span><span style="color:#65737e;"># so put it somewhere far away to avoid dividing by zero
</span><span>            energy = </span><span style="color:#d08770;">100_000
</span><span>        wavelength = </span><span style="color:#d08770;">1e8 </span><span>/ energy  </span><span style="color:#65737e;"># in angstroms
</span><span>        stick_coeff = </span><span style="color:#d08770;">2 </span><span>* np.pi / wavelength
</span><span>        </span><span style="color:#b48ead;">for </span><span>j </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n_pigs):
</span><span>            </span><span style="color:#b48ead;">for </span><span>k </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n_pigs):
</span><span>                r = pigs[j].pos - pigs[k].pos
</span><span>                </span><span style="color:#65737e;"># NumPy cross product function is super slow for small arrays
</span><span>                </span><span style="color:#65737e;"># so we do it by hand for &gt;10x speedup.
</span><span>                mu_cross = np.</span><span style="color:#bf616a;">empty</span><span>(</span><span style="color:#d08770;">3</span><span>)
</span><span>                mu_cross[</span><span style="color:#d08770;">0</span><span>] = pigs[j].mu[</span><span style="color:#d08770;">1</span><span>] * pigs[k].mu[</span><span style="color:#d08770;">2</span><span>] - pigs[j].mu[</span><span style="color:#d08770;">2</span><span>] * pigs[k].mu[</span><span style="color:#d08770;">1</span><span>]
</span><span>                mu_cross[</span><span style="color:#d08770;">1</span><span>] = pigs[j].mu[</span><span style="color:#d08770;">2</span><span>] * pigs[k].mu[</span><span style="color:#d08770;">0</span><span>] - pigs[j].mu[</span><span style="color:#d08770;">0</span><span>] * pigs[k].mu[</span><span style="color:#d08770;">2</span><span>]
</span><span>                mu_cross[</span><span style="color:#d08770;">2</span><span>] = pigs[j].mu[</span><span style="color:#d08770;">0</span><span>] * pigs[k].mu[</span><span style="color:#d08770;">1</span><span>] - pigs[j].mu[</span><span style="color:#d08770;">1</span><span>] * pigs[k].mu[</span><span style="color:#d08770;">0</span><span>] 
</span><span>                stick_cd[i] += e_vecs[j, i] * e_vecs[k, i] * np.</span><span style="color:#bf616a;">dot</span><span>(r, mu_cross)
</span><span>        stick_cd[i] *= stick_coeff
</span><span>    out = {
</span><span>        &quot;</span><span style="color:#a3be8c;">ham_deleted</span><span>&quot;: ham,
</span><span>        &quot;</span><span style="color:#a3be8c;">pigs_deleted</span><span>&quot;: pigs,
</span><span>        &quot;</span><span style="color:#a3be8c;">e_vals</span><span>&quot;: e_vals,
</span><span>        &quot;</span><span style="color:#a3be8c;">e_vecs</span><span>&quot;: e_vecs,
</span><span>        &quot;</span><span style="color:#a3be8c;">exciton_mus</span><span>&quot;: exciton_mus,
</span><span>        &quot;</span><span style="color:#a3be8c;">stick_abs</span><span>&quot;: stick_abs,
</span><span>        &quot;</span><span style="color:#a3be8c;">stick_cd</span><span>&quot;: stick_cd
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">return </span><span>out
</span></code></pre>
<p>Even to my eyes it's not immediately obvious where the bottleneck would be in this function. In order to continue looking for the bottleneck we'll use another tool: <code>line_profiler</code>. A flamegraph tells you which function is slow, but not necessarily <em>what about it</em> is slow. <code>line_profiler</code> annotates each line with information about its execution time so you can immediately see where the time is going. Running <code>line_profiler</code> on <code>make_stick_spectrum</code> generates this report:</p>
<hr />
<details>
    <summary>Click here to expand the report</summary>
    <pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>Timer unit: 1e-06 s
</span><span>
</span><span>Total time: 0.010513 s
</span><span>File: /Users/zmitchell/code/research/fmo_analysis/fmo_analysis/exciton.py
</span><span>Function: make_stick_spectrum at line 37
</span><span>
</span><span>Line #      Hits         Time  Per Hit   % Time  Line Contents
</span><span>==============================================================
</span><span>    37                                           def make_stick_spectrum(config: Config, ham: np.ndarray, pigs: List[Pigment]) -&gt; Dict:
</span><span>    38                                               &quot;&quot;&quot;Computes the stick spectra and eigenvalues/eigenvectors for the system.&quot;&quot;&quot;
</span><span>    39         1          8.0      8.0      0.1      ham, pigs = delete_pigment(config, ham, pigs)
</span><span>    40         1          2.0      2.0      0.0      n_pigs = ham.shape[0]
</span><span>    41         1          4.0      4.0      0.0      if config.delete_pig &gt; n_pigs:
</span><span>    42                                                   raise ValueError(f&quot;Tried to delete pigment {config.delete_pig} but system only has {n_pigs} pigments.&quot;)
</span><span>    43         1        768.0    768.0      7.3      e_vals, e_vecs = np.linalg.eig(ham)
</span><span>    44         1         32.0     32.0      0.3      pig_mus = np.zeros((n_pigs, 3))
</span><span>    45         1          5.0      5.0      0.0      if config.normalize:
</span><span>    46                                                   total_dpm = np.sum([np.dot(p.mu, p.mu) for p in pigs])
</span><span>    47                                                   for i in range(len(pigs)):
</span><span>    48                                                       pigs[i].mu /= total_dpm
</span><span>    49         8         36.0      4.5      0.3      for i, p in enumerate(pigs):
</span><span>    50         7         63.0      9.0      0.6          pig_mus[i, :] = pigs[i].mu
</span><span>    51         1         46.0     46.0      0.4      exciton_mus = np.zeros_like(pig_mus)
</span><span>    52         1          3.0      3.0      0.0      stick_abs = np.zeros(n_pigs)
</span><span>    53         1          3.0      3.0      0.0      stick_cd = np.zeros(n_pigs)
</span><span>    54         8         12.0      1.5      0.1      for i in range(n_pigs):
</span><span>    55         7        478.0     68.3      4.5          exciton_mus[i, :] = np.sum(np.repeat(e_vecs[:, i], 3).reshape((n_pigs, 3)) * pig_mus, axis=0)
</span><span>    56         7         84.0     12.0      0.8          stick_abs[i] = np.dot(exciton_mus[i], exciton_mus[i])
</span><span>    57         7         10.0      1.4      0.1          energy = e_vals[i]
</span><span>    58         7         23.0      3.3      0.2          if energy == 0:
</span><span>    59                                                       # If the energy is zero, the pigment has been deleted
</span><span>    60                                                       energy = 100_000
</span><span>    61         7         14.0      2.0      0.1          wavelength = 1e8 / energy  # in angstroms
</span><span>    62         7         15.0      2.1      0.1          stick_coeff = 2 * np.pi / wavelength
</span><span>    63        56        102.0      1.8      1.0          for j in range(n_pigs):
</span><span>    64       392        689.0      1.8      6.6              for k in range(n_pigs):
</span><span>    65       343       1167.0      3.4     11.1                  r = pigs[j].pos - pigs[k].pos
</span><span>    66                                                           # NumPy cross product function is super slow for small arrays
</span><span>    67                                                           # so we do it by hand for &gt;10x speedup. It makes a difference!
</span><span>    68       343       1112.0      3.2     10.6                  mu_cross = np.empty(3)
</span><span>    69       343       1230.0      3.6     11.7                  mu_cross[0] = pigs[j].mu[1] * pigs[k].mu[2] - pigs[j].mu[2] * pigs[k].mu[1]
</span><span>    70       343        953.0      2.8      9.1                  mu_cross[1] = pigs[j].mu[2] * pigs[k].mu[0] - pigs[j].mu[0] * pigs[k].mu[2]
</span><span>    71       343       1020.0      3.0      9.7                  mu_cross[2] = pigs[j].mu[0] * pigs[k].mu[1] - pigs[j].mu[1] * pigs[k].mu[0] 
</span><span>    72       343       2611.0      7.6     24.8                  stick_cd[i] += e_vecs[j, i] * e_vecs[k, i] * np.dot(r, mu_cross)
</span><span>    73         7         11.0      1.6      0.1          stick_cd[i] *= stick_coeff
</span><span>    74         1          3.0      3.0      0.0      out = {
</span><span>    75         1          1.0      1.0      0.0          &quot;ham_deleted&quot;: ham,
</span><span>    76         1          1.0      1.0      0.0          &quot;pigs_deleted&quot;: pigs,
</span><span>    77         1          1.0      1.0      0.0          &quot;e_vals&quot;: e_vals,
</span><span>    78         1          1.0      1.0      0.0          &quot;e_vecs&quot;: e_vecs,
</span><span>    79         1          1.0      1.0      0.0          &quot;exciton_mus&quot;: exciton_mus,
</span><span>    80         1          2.0      2.0      0.0          &quot;stick_abs&quot;: stick_abs,
</span><span>    81         1          1.0      1.0      0.0          &quot;stick_cd&quot;: stick_cd
</span><span>    82                                               }
</span><span>    83         1          1.0      1.0      0.0      return out
</span></code></pre>

</details>
<hr />
<p>This is what we learn from the report:</p>
<ul>
<li>7.3% diagonalizing the Hamiltonian (line 43)</li>
<li>4.5% computing exciton dipole moments (line 55)</li>
<li>0.8% computing stick absorption (line 56)</li>
<li>77% computing stick CD (lines 65-72)</li>
</ul>
<p>So, let's focus on computing CD!</p>
<h2 id="optimizing-cd">Optimizing CD</h2>
<p>At this point I decided to make myself some tools. I made a script for running <code>line_profiler</code> and a script for timing the execution of a single function, then checked both of these into git so that I can reuse them at a later date without needing to reinvent the wheel.</p>
<p>My execution timing script boils down to this:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">from </span><span>time </span><span style="color:#b48ead;">import </span><span>perf_counter
</span><span style="color:#b48ead;">from </span><span>fmo_analysis </span><span style="color:#b48ead;">import </span><span>exciton
</span><span>
</span><span>
</span><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">main</span><span>():
</span><span>    ham, pigs = </span><span style="color:#d08770;">...
</span><span>    n = </span><span style="color:#d08770;">10_000
</span><span>    times = []
</span><span>    </span><span style="color:#b48ead;">for </span><span style="color:#bf616a;">_ </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n):
</span><span>        t_start = </span><span style="color:#bf616a;">perf_counter</span><span>()
</span><span>        stick = exciton.</span><span style="color:#bf616a;">make_stick_spectrum</span><span>(config, ham, pigs)
</span><span>        t_stop = </span><span style="color:#bf616a;">perf_counter</span><span>()
</span><span>        times.</span><span style="color:#bf616a;">append</span><span>(t_stop - t_start)
</span><span>    per_call = </span><span style="color:#96b5b4;">sum</span><span>(times) / n * </span><span style="color:#d08770;">1e3
</span><span>    </span><span style="color:#96b5b4;">print</span><span>(</span><span style="color:#b48ead;">f</span><span>&quot;{per_call</span><span style="color:#d08770;">:.4f</span><span>}</span><span style="color:#a3be8c;">ms per call</span><span>&quot;)
</span><span>
</span><span>
</span><span style="color:#b48ead;">if </span><span>__name__ == &quot;</span><span style="color:#a3be8c;">__main__</span><span>&quot;:
</span><span>    </span><span style="color:#bf616a;">main</span><span>()
</span></code></pre>
<p>The execution time varies from moment to moment depending on what else is running on my laptop, what's in cache, etc so the exact times should be taken with a grain of salt. Our starting point is 3.48ms per call to <code>make_stick_spectrum</code>.</p>
<h3 id="avoiding-superfluous-lookups">Avoiding superfluous lookups</h3>
<p>The first thing that jumped out at me is that we're repeatedly looking up the two pigments <code>pigs[j]</code> and <code>pigs[k]</code> in the inner loop. Looking these pigments up once at the beginning of the loop e.g. <code>pig_j = pigs[j]</code> takes us from 3.48ms to 2.78ms for a 25% speedup.</p>
<p>The CD calculation now looks like this for a single &quot;stick&quot;:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">for </span><span>j </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n_pigs):
</span><span>    </span><span style="color:#b48ead;">for </span><span>k </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n_pigs):
</span><span>        pig_j = pigs[j]
</span><span>        pig_k = pigs[k]
</span><span>        r = pig_j.pos - pig_k.pos
</span><span>        </span><span style="color:#65737e;"># NumPy cross product function is super slow for small arrays
</span><span>        </span><span style="color:#65737e;"># so we do it by hand for &gt;10x speedup.
</span><span>        mu_cross = np.</span><span style="color:#bf616a;">empty</span><span>(</span><span style="color:#d08770;">3</span><span>)
</span><span>        mu_j = pig_j.mu
</span><span>        mu_k = pig_k.mu
</span><span>        mu_cross[</span><span style="color:#d08770;">0</span><span>] = mu_j[</span><span style="color:#d08770;">1</span><span>] * mu_k[</span><span style="color:#d08770;">2</span><span>] - mu_j[</span><span style="color:#d08770;">2</span><span>] * mu_k[</span><span style="color:#d08770;">1</span><span>]
</span><span>        mu_cross[</span><span style="color:#d08770;">1</span><span>] = mu_j[</span><span style="color:#d08770;">2</span><span>] * mu_k[</span><span style="color:#d08770;">0</span><span>] - mu_j[</span><span style="color:#d08770;">0</span><span>] * mu_k[</span><span style="color:#d08770;">2</span><span>]
</span><span>        mu_cross[</span><span style="color:#d08770;">2</span><span>] = mu_j[</span><span style="color:#d08770;">0</span><span>] * mu_k[</span><span style="color:#d08770;">1</span><span>] - mu_j[</span><span style="color:#d08770;">1</span><span>] * mu_k[</span><span style="color:#d08770;">0</span><span>]
</span><span>        </span><span style="color:#65737e;"># Calculate the dot product by hand, 2x faster than np.dot()
</span><span>        r_mu_dot = r[</span><span style="color:#d08770;">0</span><span>] * mu_cross[</span><span style="color:#d08770;">0</span><span>] + r[</span><span style="color:#d08770;">1</span><span>] * mu_cross[</span><span style="color:#d08770;">1</span><span>] + r[</span><span style="color:#d08770;">2</span><span>] * mu_cross[</span><span style="color:#d08770;">2</span><span>]
</span><span>        stick_cd[i] += e_vecs[j, i] * e_vecs[k, i] * r_mu_dot
</span></code></pre>
<h3 id="skipping-half-of-the-calculations">Skipping half of the calculations</h3>
<p>It turns out that the computation for a pair of pigments <code>j</code> and <code>k</code> is identical to the computation for <code>k</code> and <code>j</code>. Put another way, if you swap <code>j</code> and <code>k</code> nothing changes. Swapping <code>r_j</code> and <code>r_k</code> gives you a minus sign. Swapping <code>mu_j</code> and <code>mu_k</code> also gives you a minus sign. These two minus signs cancel out when you calculate <code>(r_j - r_k) * (mu_j x mu_k)</code>. This means we only need to calculate the CD contribution for each pair of pigments once and then double it (i.e. <code>2 * cd(j,k)</code>) rather than calculating it separately for <code>j,k</code> and <code>k,j</code> (i.e. <code>cd(j,k) + cd(k,j)</code>).</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">for </span><span>j </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n_pigs):
</span><span>    </span><span style="color:#b48ead;">for </span><span>k </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(j, n_pigs):  </span><span style="color:#65737e;"># Notice the &quot;j&quot; here now!
</span><span>        </span><span style="color:#d08770;">...
</span><span>        </span><span style="color:#65737e;"># Notice the &quot;2&quot; here now!
</span><span>        stick_cd[i] += </span><span style="color:#d08770;">2 </span><span>* e_vecs[j, i] * e_vecs[k, i] * r_mu_dot
</span></code></pre>
<p>This takes us from 2.78ms to 1.71ms for a 63% speedup.</p>
<h3 id="skipping-the-diagonal">Skipping the diagonal</h3>
<p>The key calculation is this <code>(r_j - r_k) * (mu_j x mu_k)</code> piece. Both <code>(r_j - r_k)</code> and <code>(mu_j x mu_k)</code> are zero if <code>j = k</code>, so we can skip those calculations entirely. This is all we need to change:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">for </span><span>j </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n_pigs):
</span><span>    </span><span style="color:#b48ead;">for </span><span>k </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(j+</span><span style="color:#d08770;">1</span><span>, n_pigs):  </span><span style="color:#65737e;"># Notice the &quot;+1&quot; here!
</span></code></pre>
<p>This takes us from 1.71ms to 1.41ms for an 21% speedup.</p>
<h3 id="caching-some-computations">Caching some computations</h3>
<p>If you look at the <code>(r_j - r_k) * (mu_j x mu_k)</code> piece, you'll notice a distinct lack of <code>i</code>. This means we're calculating it over and over again for no reason on every iteration of the outer loop. We can calculate this part once and reuse it. The outer loop looks like this now:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>r_mu_cross_cache = </span><span style="color:#bf616a;">make_r_dot_mu_cross_cache</span><span>(pigs)
</span><span style="color:#b48ead;">for </span><span>i </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n_pigs):
</span><span>    exciton_mus[i, :] = np.</span><span style="color:#bf616a;">sum</span><span>(np.</span><span style="color:#bf616a;">repeat</span><span>(e_vecs[:, i], </span><span style="color:#d08770;">3</span><span>).</span><span style="color:#bf616a;">reshape</span><span>((n_pigs, </span><span style="color:#d08770;">3</span><span>)) * pig_mus, </span><span style="color:#bf616a;">axis</span><span>=</span><span style="color:#d08770;">0</span><span>)
</span><span>    stick_abs[i] = np.</span><span style="color:#bf616a;">dot</span><span>(exciton_mus[i], exciton_mus[i])
</span><span>    energy = e_vals[i]
</span><span>    </span><span style="color:#b48ead;">if </span><span>energy == </span><span style="color:#d08770;">0</span><span>:
</span><span>        </span><span style="color:#65737e;"># If the energy is zero, the pigment has been deleted
</span><span>        energy = </span><span style="color:#d08770;">100_000
</span><span>    wavelength = </span><span style="color:#d08770;">1e8 </span><span>/ energy  </span><span style="color:#65737e;"># in angstroms
</span><span>    stick_coeff = </span><span style="color:#d08770;">2 </span><span>* np.pi / wavelength
</span><span>    e_vec_weights = </span><span style="color:#bf616a;">make_weight_matrix</span><span>(e_vecs, i)
</span><span>    stick_cd[i] = </span><span style="color:#d08770;">2 </span><span>* stick_coeff * np.</span><span style="color:#bf616a;">sum</span><span>(e_vec_weights * r_mu_cross_cache)
</span></code></pre>
<p>where <code>make_r_mu_cross_cache</code> and <code>make_weight_matrix</code> look like this:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">make_r_dot_mu_cross_cache</span><span>(</span><span style="color:#bf616a;">pigs</span><span>):
</span><span>    </span><span style="color:#65737e;">&quot;&quot;&quot;Computes a cache of (r_i - r_j) * (mu_i x mu_j)&quot;&quot;&quot;
</span><span>    n = </span><span style="color:#96b5b4;">len</span><span>(pigs)
</span><span>    cache = np.</span><span style="color:#bf616a;">zeros</span><span>((n, n))
</span><span>    </span><span style="color:#b48ead;">for </span><span>i </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n):
</span><span>        </span><span style="color:#b48ead;">for </span><span>j </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(i+</span><span style="color:#d08770;">1</span><span>, n):
</span><span>            r_i = pigs[i].pos
</span><span>            r_j = pigs[j].pos
</span><span>            r_ij = r_i - r_j
</span><span>            mu_i = pigs[i].mu
</span><span>            mu_j = pigs[j].mu
</span><span>            mu_ij_cross = np.</span><span style="color:#bf616a;">empty</span><span>(</span><span style="color:#d08770;">3</span><span>)
</span><span>            mu_ij_cross[</span><span style="color:#d08770;">0</span><span>] = mu_i[</span><span style="color:#d08770;">1</span><span>] * mu_j[</span><span style="color:#d08770;">2</span><span>] - mu_i[</span><span style="color:#d08770;">2</span><span>] * mu_j[</span><span style="color:#d08770;">1</span><span>]
</span><span>            mu_ij_cross[</span><span style="color:#d08770;">1</span><span>] = mu_i[</span><span style="color:#d08770;">2</span><span>] * mu_j[</span><span style="color:#d08770;">0</span><span>] - mu_i[</span><span style="color:#d08770;">0</span><span>] * mu_j[</span><span style="color:#d08770;">2</span><span>]
</span><span>            mu_ij_cross[</span><span style="color:#d08770;">2</span><span>] = mu_i[</span><span style="color:#d08770;">0</span><span>] * mu_j[</span><span style="color:#d08770;">1</span><span>] - mu_i[</span><span style="color:#d08770;">1</span><span>] * mu_j[</span><span style="color:#d08770;">0</span><span>]
</span><span>            cache[i, j] = r_ij[</span><span style="color:#d08770;">0</span><span>] * mu_ij_cross[</span><span style="color:#d08770;">0</span><span>] + r_ij[</span><span style="color:#d08770;">1</span><span>] * mu_ij_cross[</span><span style="color:#d08770;">1</span><span>] + r_ij[</span><span style="color:#d08770;">2</span><span>] * mu_ij_cross[</span><span style="color:#d08770;">2</span><span>]
</span><span>    </span><span style="color:#b48ead;">return </span><span>cache
</span><span>
</span><span>
</span><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">make_weight_matrix</span><span>(</span><span style="color:#bf616a;">e_vecs</span><span>, </span><span style="color:#bf616a;">col</span><span>):
</span><span>    </span><span style="color:#65737e;">&quot;&quot;&quot;Makes the matrix of weights for CD from the eigenvectors&quot;&quot;&quot;
</span><span>    n = e_vecs.shape[</span><span style="color:#d08770;">0</span><span>]
</span><span>    mat = np.</span><span style="color:#bf616a;">zeros</span><span>((n, n))
</span><span>    </span><span style="color:#b48ead;">for </span><span>i </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(n):
</span><span>        </span><span style="color:#b48ead;">for </span><span>j </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(i+</span><span style="color:#d08770;">1</span><span>, n):
</span><span>            mat[i, j] = e_vecs[i, col] * e_vecs[j, col]
</span><span>    </span><span style="color:#b48ead;">return </span><span>mat
</span></code></pre>
<p>This takes us from 1.41ms to 0.94ms for a 50% speedup.</p>
<h3 id="letting-numpy-take-control">Letting NumPy take control</h3>
<p>The more you can keep execution in C and out of Python, the faster your program is going to run. In practice this means letting NumPy do iteration for you and apply functions to entire arrays since it can iterate and apply functions in C, which is much faster. Consider this example: I want to multiply two matrices together elementwise and sum the result.</p>
<p>The naive version looks like this:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>np.</span><span style="color:#bf616a;">sum</span><span>(e_vec_weights * r_mu_cross_cache)
</span></code></pre>
<p>The product here creates a new array containing the product, and <code>np.sum</code> adds the elements of that new matrix.</p>
<p>There's another operation similar to this called the &quot;dot product&quot; or &quot;inner product&quot;, but in order to get a single number out of it you need two 1D arrays. Luckily there's a built-in method, <code>flatten</code>, which converts a multi-dimensional array into a 1D array. Since these two matrices are the same shape I know they'll be flattened such that corresponding elements line up properly for the dot product:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>np.</span><span style="color:#bf616a;">dot</span><span>(e_vec_weights.</span><span style="color:#bf616a;">flatten</span><span>(), r_mu_cross_cache.</span><span style="color:#bf616a;">flatten</span><span>())
</span></code></pre>
<p>This is roughly 3x faster than the naive method. It's not a big speedup overall in this program (0.94ms to 0.91ms for a 3% speedup) but it's instructive anyway.</p>
<h2 id="calling-lapack-routines-directly">Calling LAPACK routines directly</h2>
<p>At this point the breakdown of execution time looks like this:</p>
<ul>
<li>50% computing eigenvalues and eigenvectors</li>
<li>16% making the cache</li>
<li>9% making the weights to go along with the cache</li>
<li>10% computing the exciton dipole moments</li>
</ul>
<p>Calculating CD no longer dominates the execution time, so I moved my focus to diagonalization. I knew that my Hamiltonian matrix was <a href="https://en.wikipedia.org/wiki/Symmetric_matrix">symmetric</a>, so I wondered if there were diagonalization algorithms that could take advantage of this. Fortunately NumPy has one built in: <code>eigh</code>. Unfortunately it didn't seem to make much of a difference (within measurement error on my laptop). I suspect that there may be a bigger difference on a larger matrix.</p>
<p>I wondered again whether NumPy was adding some overhead. One of the things that makes NumPy so fast is that parts of it are wrappers around <a href="https://en.wikipedia.org/wiki/LAPACK">LAPACK</a> and <a href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms">BLAS</a>, which are industry standard libraries for efficient linear algebra algorithms and operations. In order to test out this hypothesis I decided to call the LAPACK diagonalization routine directly as made available by the <code>scipy.lapack</code> module. The LAPACK routine used by <code>eig</code> is called DGEEV. Yeah, it's cryptic.</p>
<p>A tricky detail here is that LAPACK is written in FORTRAN, so it expects and returns arrays with FORTRAN-ordering (column-major) rather than C-ordering (row-major), so you need to handle conversion between the two. Fortunately my Hamiltonian is symmetric so the FORTRAN ordering is actually identical to the C-ordering. This isn't the case for the return values, though.</p>
<p>This is what the new diagonalization code looks like:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>e_vals_fortran_order, </span><span style="color:#bf616a;">_</span><span>, </span><span style="color:#bf616a;">_</span><span>, e_vecs_fortran_order, </span><span style="color:#bf616a;">_ </span><span>= lapack.</span><span style="color:#bf616a;">sgeev</span><span>(ham)
</span><span>e_vals = np.</span><span style="color:#bf616a;">ascontiguousarray</span><span>(e_vals_fortran_order)
</span><span>e_vecs = np.</span><span style="color:#bf616a;">ascontiguousarray</span><span>(e_vecs_fortran_order)
</span></code></pre>
<p>This takes us from 0.91ms to 0.85ms for a 7% speedup.</p>
<p>At this point we've managed to reduce the execution time from 3.48ms to 0.85ms for a 4x speedup. The goal is 100x, so we're missing our target by 25x. That's a lot of x's and I'm running out of NumPy tricks. It's time to call in the big guns.</p>
<h2 id="rust-rewrite">Rust rewrite</h2>
<p>I know it's a meme at this point, but I decided to rewrite the number-crunching parts of this program in Rust. There are four crates that make this possible:</p>
<ul>
<li><a href="https://github.com/PyO3/pyo3">PyO3</a>, for Rust/Python interop</li>
<li><a href="https://github.com/PyO3/maturin">maturin</a>, for interacting with your extension during development and eventually publishing it to PyPI</li>
<li><a href="https://github.com/rust-ndarray/ndarray">ndarray</a>, Rust's equivalent to NumPy</li>
<li><a href="https://github.com/PyO3/rust-numpy">rust-numpy</a>, for converting between NumPy and ndarray</li>
</ul>
<p>The Python interop was shockingly easy. I wouldn't even know how to begin doing this with C. It's not without friction, but that's mostly a documentation issue. For instance, I had trouble putting my Rust source alongside my Python source in my Python package and having <code>poetry build</code> include the compiled Rust binary. The documentation makes it sound like this is the preferred method, but I couldn't figure it out in the moment and I was short on time. It's entirely possible I missed something simple, I've never done this before.</p>
<p>I ended up just making a separate package, <a href="https://github.com/savikhin-lab/ham2spec">ham2spec</a>, so I could upload it to PyPI and have it downloaded and installed like any other dependency. I shouldn't have to build and upload my Rust extension to a server somewhere to get it picked up properly as a dependency of my local project, but here we are.</p>
<p>This is what the development process looks like:</p>
<ul>
<li>Create a new project with <code>maturin new</code></li>
<li>Write your Rust code</li>
<li>Package it up and expose it to Python locally with <code>maturin develop</code></li>
<li>Fire up a Python interpreter and play around with your module to give things a cursory glance</li>
<li>Repeat</li>
<li>Publish your module with <code>maturin publish</code></li>
</ul>
<p>I also decided to interface with LAPACK directly via the <a href="https://github.com/blas-lapack-rs/blas-lapack-rs.github.io/wiki">lapack</a> crate. I have one use of <code>unsafe</code> in my crate and it's the call to <code>dgeev</code>. I'm ok with that.</p>
<p>The Rust code is a pretty direct translation from the Python code. I had an inkling from the beginning that I would need to write the number crunching code in Rust, but it was easier to explore optimizations in Python first. The only real deviations are the use of all the nice iterators that Rust provides, especially the <code>Zip</code> iterator that ndarray provides for iterating over multiple arrays in lock-step. Here's <code>Zip</code> in action:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">compute_stick_spectra</span><span>(
</span><span>    </span><span style="color:#bf616a;">hams</span><span>: ArrayView3&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>    </span><span style="color:#bf616a;">mus</span><span>: ArrayView3&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>    </span><span style="color:#bf616a;">rs</span><span>: ArrayView3&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>) -&gt; Vec&lt;StickSpectrum&gt; {
</span><span>    </span><span style="color:#b48ead;">let</span><span> dummy_stick = StickSpectrum {
</span><span>        e_vals: </span><span style="color:#96b5b4;">arr1</span><span>(&amp;[]),
</span><span>        e_vecs: </span><span style="color:#96b5b4;">arr2</span><span>(&amp;[[], []]),
</span><span>        mus: </span><span style="color:#96b5b4;">arr2</span><span>(&amp;[[], []]),
</span><span>        stick_abs: </span><span style="color:#96b5b4;">arr1</span><span>(&amp;[]),
</span><span>        stick_cd: </span><span style="color:#96b5b4;">arr1</span><span>(&amp;[]),
</span><span>    };
</span><span>    </span><span style="color:#b48ead;">let mut</span><span> sticks: Vec&lt;StickSpectrum&gt; = Vec::with_capacity(hams.</span><span style="color:#96b5b4;">dim</span><span>().</span><span style="color:#d08770;">0</span><span>);
</span><span>    sticks.</span><span style="color:#96b5b4;">resize</span><span>(hams.</span><span style="color:#96b5b4;">dim</span><span>().</span><span style="color:#d08770;">0</span><span>, dummy_stick);
</span><span>    Zip::from(hams.</span><span style="color:#96b5b4;">axis_iter</span><span>(Axis(</span><span style="color:#d08770;">0</span><span>)))
</span><span>        .</span><span style="color:#96b5b4;">and</span><span>(mus.</span><span style="color:#96b5b4;">axis_iter</span><span>(Axis(</span><span style="color:#d08770;">0</span><span>)))
</span><span>        .</span><span style="color:#96b5b4;">and</span><span>(rs.</span><span style="color:#96b5b4;">axis_iter</span><span>(Axis(</span><span style="color:#d08770;">0</span><span>)))
</span><span>        .</span><span style="color:#96b5b4;">and</span><span>(&amp;</span><span style="color:#b48ead;">mut</span><span> sticks)
</span><span>        .</span><span style="color:#96b5b4;">for_each</span><span>(|</span><span style="color:#bf616a;">h</span><span>, </span><span style="color:#bf616a;">m</span><span>, </span><span style="color:#bf616a;">r</span><span>, </span><span style="color:#bf616a;">s</span><span>| *s = </span><span style="color:#96b5b4;">compute_stick_spectrum</span><span>(h, m, r));
</span><span>    sticks
</span><span>}
</span></code></pre>
<p>This direct translation executes in 35us for a total speedup of ~100x, but there's a bit of a catch. The Rust code takes 3 arrays as arguments (8x8 Hamiltonian, 8x3 dipole moments, 8x3 positions), whereas the previous Python function is called with an 8x8 array for the Hamiltonian and a list of <code>Pigment</code> objects, which are each just containers for a position and a dipole moment. Doing the conversion to arrays brings the execution time to 45us. I'm still counting this as a win since I don't <em>have</em> to do this conversion, I'm just doing it to preserve backwards compatibility with a bunch of simulations I've already written.</p>
<p>Just for kicks I decided to profile <code>ham2spec</code> to see if there was any low-hanging fruit for optimization. In order to do this I had to create a crate example since my crate is a library, not a binary, and examples get compiled into their own binaries. I made this example and profiled it with <code>cargo-flamegraph</code>. The profiling output showed that the runtime of <code>compute_stick_spectrum</code> (my Rust equivalent of the <code>make_stick_spectrum</code> function from my Python code) looked like this:</p>
<ul>
<li>45% diagonalization</li>
<li>23% computing exciton dipole moments</li>
<li>24% computing CD</li>
</ul>
<p>If I could somehow magically eliminate my own calculations entirely and let diagonalization dominate the execution time I would only make this function ~2x faster. I already know that we've eliminated the stick spectrum bottleneck, so this isn't worth it.</p>
<p>The only thing left to do is make sure the output of the new code and old code match up...</p>
<h2 id="matching-outputs">Matching outputs</h2>
<p>It's at this point that I must make a confession. I haven't been eating my vegetables. Well, I have, like I said I'm a vegetarian. What I really mean is that I didn't have a test suite for either <code>fmo_analysis</code> or <code>ham2spec</code>. I know, blasphemy.</p>
<p>I'm the last person you need to convince about writing tests. I've <a href="https://www.youtube.com/watch?v=RdpHONoFsSs&amp;list=PLgC1L0fKd7UkVwjVlOySfMnn80Qs5TOLb&amp;index=9">given talks</a> about esoteric testing techniques. I've also <a href="https://tinkering.xyz/polsim/#testing">written about</a> the need for better testing in scientific software and <a href="https://tinkering.xyz/property-based-testing-with-proptest">property-based testing specifically</a>. So, how did we get here?</p>
<ul>
<li>Burnout. Graduate school is hard. Doing anything that doesn't directly move you towards graduation has a high activation energy.</li>
<li>I'm the only person on the planet using this software, so I'll just run into all the bugs myself and fix them. Right?</li>
<li>This started as a small CLI that I threw together and it quickly grew beyond that scope.</li>
<li>My dog ate my test suite.</li>
</ul>
<p>Suffice to say that I now have test suites for both <code>fmo_analysis</code> and <code>ham2spec</code>.</p>
<p>The problem was multi-faceted:</p>
<ul>
<li>I wasn't converting between memory orderings correctly</li>
<li>Eigenvectors are only defined up to a sign, so small differences in precision can cause sign flips</li>
<li>I had switched from double-precision to single-precision, which caused sign flips as mentioned above</li>
<li>The allegedly &quot;known-good&quot; data I was comparing against was saved incorrectly (when in doubt, test the test!)</li>
</ul>
<p>Ultimately the sign flips don't change the results, but I had to change my test suite to allow for sign flips.</p>
<hr />
<details>
    <summary>Aside: Converting between orderings</summary>
    <p>An <code>n</code>-dimensional array in NumPy or ndarray consists of a few pieces of information:</p>
<ul>
<li>The buffer containing the actual data</li>
<li>The dimensions of the array</li>
<li>The strides, or &quot;how many elements do I have to traverse in the buffer to get to the next item along a particular axis&quot;</li>
</ul>
<p>You can see that <a href="https://github.com/rust-ndarray/ndarray/blob/307234e71dac87d72d7c1d955ed9f68e5e902623/src/lib.rs#L1285">here in ndarray</a> and <a href="https://numpy.org/devdocs/reference/c-api/types-and-structures.html#c.PyArrayObject">here in NumPy</a>.</p>
<p>When you ask for the transpose of an array (swapping the rows and columns) it's these dimensions and strides that are modified, not the underlying data. For instance, this is how <code>ndarray::ArrayBase::reversed_axes</code> is implemented:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#65737e;">/// Transpose the array by reversing axes.
</span><span style="color:#65737e;">///
</span><span style="color:#65737e;">/// Transposition reverses the order of the axes (dimensions and strides)
</span><span style="color:#65737e;">/// while retaining the same data.
</span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">reversed_axes</span><span>(</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>) -&gt; ArrayBase&lt;S, D&gt; {
</span><span>    </span><span style="color:#bf616a;">self</span><span>.dim.</span><span style="color:#96b5b4;">slice_mut</span><span>().</span><span style="color:#96b5b4;">reverse</span><span>();
</span><span>    </span><span style="color:#bf616a;">self</span><span>.strides.</span><span style="color:#96b5b4;">slice_mut</span><span>().</span><span style="color:#96b5b4;">reverse</span><span>();
</span><span>    </span><span style="color:#bf616a;">self
</span><span>}
</span></code></pre>
<p>This is a good idea because the data structures for dimensions and strides are small and quickly modified. Copying the contents of the array into a new array in a different order is much slower. In order to actually transpose the data in the buffer you have to do this:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">let</span><span> transposed = my_arr
</span><span>    .</span><span style="color:#96b5b4;">reversed_axes</span><span>()
</span><span>    .</span><span style="color:#96b5b4;">as_standard_layout</span><span>()  </span><span style="color:#65737e;">// Returns a CowArray (Cow = copy-on-write)
</span><span>    .</span><span style="color:#96b5b4;">to_owned</span><span>();  </span><span style="color:#65737e;">// Necessary to get an owned array
</span></code></pre>

</details>
<hr /><h2 id="broadened-spectra">Broadened spectra</h2>
<p>Once everything was <em>correct</em>, I got back to work optimizing. My stick spectrum computations were 100x faster, so it was time to look at how that translated to computing a broadened spectrum. As a refresher, computing a broadened spectrum looks like this:</p>
<ul>
<li>Compute the stick spectrum from a Hamiltonian</li>
<li>Compute a broadened spectrum from a stick spectrum</li>
</ul>
<p>I timed the execution of the original system computing a spectrum from 100 Hamiltonians and it took 381ms. It's no wonder that a fit takes forever when each iteration of the minimization routine takes almost 400ms.</p>
<p>I timed the execution of the new system doing the same computation and it took 40ms. That's only 10x faster! My stick spectrum computations were 100x faster than the old version, so why is this so much slower? As a reminder, this was the original breakdown of execution time:</p>
<ul>
<li>87.5% <code>make_stick_spectrum</code></li>
<li>10% <code>make_broadened_spectrum</code></li>
</ul>
<p>If you magically eliminate the runtime of everything but <code>make_broadened_spectrum</code> you would only expect a 10x speedup (100% -&gt; 10%).
We effectively <em>did</em> elminate the execution time of everything else, so we're seeing exactly that 10x speedup we would expect. So, how do we make it faster?</p>
<h3 id="making-it-parallel">Making it parallel</h3>
<p>The process of computing a broadened spectrum from each Hamiltonian falls into the category of <a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel">embarrassingly parallel</a>, so we don't even need to do much work to make this parallel. I literally changed a <code>for_each</code> to a <code>par_for_each</code>:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span>Zip::from(abs_arr.</span><span style="color:#96b5b4;">columns_mut</span><span>())
</span><span>    .</span><span style="color:#96b5b4;">and</span><span>(cd_arr.</span><span style="color:#96b5b4;">columns_mut</span><span>())
</span><span>    .</span><span style="color:#96b5b4;">and</span><span>(hams.</span><span style="color:#96b5b4;">axis_iter</span><span>(Axis(</span><span style="color:#d08770;">0</span><span>)))
</span><span>    .</span><span style="color:#96b5b4;">and</span><span>(mus.</span><span style="color:#96b5b4;">axis_iter</span><span>(Axis(</span><span style="color:#d08770;">0</span><span>)))
</span><span>    .</span><span style="color:#96b5b4;">and</span><span>(rs.</span><span style="color:#96b5b4;">axis_iter</span><span>(Axis(</span><span style="color:#d08770;">0</span><span>)))
</span><span>    .</span><span style="color:#96b5b4;">par_for_each</span><span>(|</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">abs_col</span><span>, </span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">cd_col</span><span>, </span><span style="color:#bf616a;">h</span><span>, </span><span style="color:#bf616a;">m</span><span>, </span><span style="color:#bf616a;">r</span><span>| { </span><span style="color:#65737e;">// &lt;-- parallel iteration here!
</span><span>        </span><span style="color:#b48ead;">let</span><span> stick = </span><span style="color:#96b5b4;">compute_stick_spectrum</span><span>(h, m, r);
</span><span>        </span><span style="color:#b48ead;">let</span><span> broadened = </span><span style="color:#96b5b4;">compute_broadened_spectrum_from_stick</span><span>(
</span><span>            stick.e_vals.</span><span style="color:#96b5b4;">view</span><span>(),
</span><span>            stick.stick_abs.</span><span style="color:#96b5b4;">view</span><span>(),
</span><span>            stick.stick_cd.</span><span style="color:#96b5b4;">view</span><span>(),
</span><span>            config,
</span><span>        );
</span><span>        abs_col.</span><span style="color:#96b5b4;">assign</span><span>(&amp;broadened.abs);
</span><span>        cd_col.</span><span style="color:#96b5b4;">assign</span><span>(&amp;broadened.cd);
</span><span>    });
</span><span>}
</span></code></pre>
<p>This brought the execution time from 40ms to 17.6ms for a 127% speedup. My puny laptop only has 2 cores (but it does have Hyper-threading), so this is in the ballpark of what I would expect. I do have a new 16&quot; Macbook Pro on the way with many more cores to throw at this, so we'll see if I get linear scaling with the number of cores or not.</p>
<p>At this point we're still only 22x faster than the original execution time of 381ms for computing a broadened spectrum from 100 Hamiltonians.</p>
<h3 id="doing-less-work">Doing less work</h3>
<p>I ran <code>cargo-flamegraph</code> on an example calculation and it showed that calls to <code>exp</code> account for 55% of the execution time. On one hand, that's not a function I can make faster by modifying its code, so that's discouraging. On the other hand it means that most of the execution time is spent doing calculations and nothing too weird.</p>
<p>I remember reading a post or a comment somewhere from Andrew Gallant, the original brain behind <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a>, that said something along the lines of &quot;one of the easiest ways to make a program faster is to make it do less work.&quot; That's always stuck with me. How does it apply here?</p>
<p>We're placing a Gaussian on top of each stick in the stick spectrum, but the contribution from each Gaussian diminishes as you get further away from the peak. If you get far enough away from the peak, the contributions become vanishingly small. If that's the case, why do those calculations at all?</p>
<p>I decided that instead of computing each Gaussian for all x-values in the domain I would only compute each Gaussian within a user-configurable range of the peak.</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#65737e;">/// Determine the indices for which you actually need to compute the contribution of a band
</span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">band_cutoff_indices</span><span>(</span><span style="color:#bf616a;">center</span><span>: </span><span style="color:#b48ead;">f64</span><span>, </span><span style="color:#bf616a;">bw</span><span>: </span><span style="color:#b48ead;">f64</span><span>, </span><span style="color:#bf616a;">cutoff</span><span>: </span><span style="color:#b48ead;">f64</span><span>, </span><span style="color:#bf616a;">xs</span><span>: &amp;[</span><span style="color:#b48ead;">f64</span><span>]) -&gt; (</span><span style="color:#b48ead;">usize</span><span>, </span><span style="color:#b48ead;">usize</span><span>) {
</span><span>    </span><span style="color:#b48ead;">let</span><span> lower = xs.</span><span style="color:#96b5b4;">partition_point</span><span>(|&amp;</span><span style="color:#bf616a;">x</span><span>| x &lt; (center - cutoff * bw));
</span><span>    </span><span style="color:#b48ead;">let</span><span> upper = xs.</span><span style="color:#96b5b4;">partition_point</span><span>(|&amp;</span><span style="color:#bf616a;">x</span><span>| x &lt; (center + cutoff * bw));
</span><span>    (lower, upper)
</span><span>}
</span><span>
</span><span style="color:#65737e;">/// Computes the band and adds it to the spectrum
</span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">add_cutoff_bands</span><span>(
</span><span>    </span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">spec</span><span>: ArrayViewMut1&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>    </span><span style="color:#bf616a;">energies</span><span>: ArrayView1&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>    </span><span style="color:#bf616a;">stick_strengths</span><span>: ArrayView1&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>    </span><span style="color:#bf616a;">bws</span><span>: &amp;[</span><span style="color:#b48ead;">f64</span><span>],
</span><span>    </span><span style="color:#bf616a;">cutoff</span><span>: </span><span style="color:#b48ead;">f64</span><span>,
</span><span>    </span><span style="color:#bf616a;">x</span><span>: ArrayView1&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>) {
</span><span>    Zip::from(energies)
</span><span>        .</span><span style="color:#96b5b4;">and</span><span>(stick_strengths)
</span><span>        .</span><span style="color:#96b5b4;">and</span><span>(bws)
</span><span>        .</span><span style="color:#96b5b4;">for_each</span><span>(|&amp;</span><span style="color:#bf616a;">e</span><span>, &amp;</span><span style="color:#bf616a;">strength</span><span>, &amp;</span><span style="color:#bf616a;">bw</span><span>| {
</span><span>            </span><span style="color:#b48ead;">let</span><span> denom = </span><span style="color:#96b5b4;">gauss_denom</span><span>(bw);
</span><span>            </span><span style="color:#b48ead;">let </span><span>(lower, upper) = </span><span style="color:#96b5b4;">band_cutoff_indices</span><span>(e, bw, cutoff, x.</span><span style="color:#96b5b4;">as_slice</span><span>().</span><span style="color:#96b5b4;">unwrap</span><span>());
</span><span>            </span><span style="color:#b48ead;">let</span><span> band = x
</span><span>                .</span><span style="color:#96b5b4;">slice</span><span>(s![lower..upper])
</span><span>                .</span><span style="color:#96b5b4;">mapv</span><span>(|</span><span style="color:#bf616a;">x_i</span><span>| strength * (-(x_i - e).</span><span style="color:#96b5b4;">powi</span><span>(</span><span style="color:#d08770;">2</span><span>) / denom).</span><span style="color:#96b5b4;">exp</span><span>());
</span><span>            spec.</span><span style="color:#96b5b4;">slice_mut</span><span>(s![lower..upper]).</span><span style="color:#96b5b4;">add_assign</span><span>(&amp;band);
</span><span>        });
</span><span>}
</span></code></pre>
<p>This takes us from 17.6ms to 8.1ms with a cutoff of 3 for a 117% speedup. Now we're sitting at 47x faster than the original.</p>
<h2 id="final-attempts">Final attempts</h2>
<p>At this point I was running out of low-hanging fruit and turned to some heavier-duty tools and shots in the dark.</p>
<h3 id="looking-at-the-assembly">Looking at the assembly</h3>
<p>I used <code>cargo-asm</code> to view the assembly (compiled with <code>--release</code>) of <code>add_cutoff_bands</code>:</p>
<pre data-lang="asm" style="background-color:#2b303b;color:#c0c5ce;" class="language-asm "><code class="language-asm" data-lang="asm"><span style="color:#8fa1b3;">ham2spec::add_cutoff_bands (src/lib.rs:</span><span style="color:#d08770;">337</span><span style="color:#8fa1b3;">):
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">push    </span><span style="color:#bf616a;">rbp
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">rbp</span><span>, </span><span style="color:#bf616a;">rsp
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">push    </span><span style="color:#bf616a;">r14
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">push    </span><span style="color:#bf616a;">rbx
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">sub     </span><span style="color:#bf616a;">rsp</span><span>, </span><span style="color:#d08770;">64
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">movsd   </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">24</span><span>], </span><span style="color:#bf616a;">xmm0
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">rax</span><span>, </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rsi</span><span>, +, </span><span style="color:#d08770;">8</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">cmp     </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rdx</span><span>, +, </span><span style="color:#d08770;">8</span><span>], </span><span style="color:#bf616a;">rax
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">jne     </span><span style="color:#8fa1b3;">LBB44_7
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">cmp     </span><span style="color:#bf616a;">rax</span><span>, </span><span style="color:#bf616a;">r8
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">jne     </span><span style="color:#8fa1b3;">LBB44_7
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">r10</span><span>, </span><span style="color:#bf616a;">rdi
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">r14</span><span>, </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rsi</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">rsi</span><span>, </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rsi</span><span>, +, </span><span style="color:#d08770;">16</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">r11</span><span>, </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rdx</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">rdi</span><span>, </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rdx</span><span>, +, </span><span style="color:#d08770;">16</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">cmp     </span><span style="color:#bf616a;">rsi</span><span>, </span><span style="color:#d08770;">1
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">sete    </span><span style="color:#bf616a;">dl
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">cmp     </span><span style="color:#bf616a;">r8</span><span>, </span><span style="color:#d08770;">2
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">setb    </span><span style="color:#bf616a;">al
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">or      </span><span style="color:#bf616a;">dl</span><span>, </span><span style="color:#bf616a;">al
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">cmp     </span><span style="color:#bf616a;">rdi</span><span>, </span><span style="color:#d08770;">1
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">sete    </span><span style="color:#bf616a;">bl
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">cmp     </span><span style="color:#bf616a;">dl</span><span>, </span><span style="color:#d08770;">1
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">jne     </span><span style="color:#8fa1b3;">LBB44_4
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">or      </span><span style="color:#bf616a;">bl</span><span>, </span><span style="color:#bf616a;">al
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">je      </span><span style="color:#8fa1b3;">LBB44_4
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">48</span><span>], </span><span style="color:#bf616a;">r14
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">40</span><span>], </span><span style="color:#bf616a;">r11
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">32</span><span>], </span><span style="color:#bf616a;">rcx
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">movaps  </span><span style="color:#bf616a;">xmm0</span><span>, </span><span style="color:#8fa1b3;">xmmword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rip</span><span>, +, </span><span style="color:#8fa1b3;">LCPI44_0</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">movaps  </span><span style="color:#8fa1b3;">xmmword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">80</span><span>], </span><span style="color:#bf616a;">xmm0
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">jmp     </span><span style="color:#8fa1b3;">LBB44_6
</span><span style="color:#8fa1b3;">LBB44_4:
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">48</span><span>], </span><span style="color:#bf616a;">r14
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">40</span><span>], </span><span style="color:#bf616a;">r11
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">32</span><span>], </span><span style="color:#bf616a;">rcx
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">80</span><span>], </span><span style="color:#bf616a;">rsi
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">72</span><span>], </span><span style="color:#bf616a;">rdi
</span><span style="color:#8fa1b3;">LBB44_6:
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#96b5b4;">qword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">64</span><span>], </span><span style="color:#d08770;">1
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">lea     </span><span style="color:#bf616a;">rdi</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">48</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">lea     </span><span style="color:#bf616a;">rsi</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">80</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">lea     </span><span style="color:#bf616a;">rcx</span><span>, [</span><span style="color:#bf616a;">rbp</span><span>, -, </span><span style="color:#d08770;">24</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">rdx</span><span>, </span><span style="color:#bf616a;">r8
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">r8</span><span>, </span><span style="color:#bf616a;">r9
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">r9</span><span>, </span><span style="color:#bf616a;">r10
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">call    </span><span style="color:#8fa1b3;">ndarray::zip::Zip&lt;P</span><span>,</span><span style="color:#8fa1b3;">D&gt;::inner
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">add     </span><span style="color:#bf616a;">rsp</span><span>, </span><span style="color:#d08770;">64
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">pop     </span><span style="color:#bf616a;">rbx
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">pop     </span><span style="color:#bf616a;">r14
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">pop     </span><span style="color:#bf616a;">rbp
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">ret
</span><span style="color:#8fa1b3;">LBB44_7:
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">lea     </span><span style="color:#bf616a;">rdi</span><span>, [</span><span style="color:#bf616a;">rip</span><span>, +, </span><span style="color:#8fa1b3;">l___unnamed_37</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">lea     </span><span style="color:#bf616a;">rdx</span><span>, [</span><span style="color:#bf616a;">rip</span><span>, +, </span><span style="color:#8fa1b3;">l___unnamed_38</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mov     </span><span style="color:#bf616a;">esi</span><span>, </span><span style="color:#d08770;">43
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">call    </span><span style="color:#8fa1b3;">core::panicking::panic
</span></code></pre>
<p>Well, all of the interesting stuff (the call to <code>for_each</code>) happens inside the call to <code>ndarray::zip::Zip&lt;P, D&gt;::inner</code> and I don't know how to get at that with <code>cargo asm</code>. I fired up a debugger and disassembled <code>add_cutoff_bands</code>, but this left me with the opposite problem (a sea of assembly). I wasn't able to glean much from this just because I can barely read assembly. Sorry.</p>
<p>I was looking for signs one way or the other whether the computations were being vectorized. It's still unclear to me whether that's happening.</p>
<h3 id="instruction-level-parallelism">Instruction level parallelism</h3>
<p>I recently read a series of posts showing how a Rust program was progressively optimized and made to run in parallel (<a href="https://parallel-rust-cpp.github.io">Comparing Parallel Rust and C++</a>) and one of the optimizations seemed relatively easy: loop unrolling.</p>
<p>I decided to give it a try by operating on chunks of data at a time, like this:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#65737e;">/// The block size for doing chunked computations
</span><span style="color:#b48ead;">const </span><span style="color:#d08770;">BLOCK_SIZE</span><span>: </span><span style="color:#b48ead;">usize </span><span>= </span><span style="color:#d08770;">4</span><span>;
</span><span>
</span><span style="color:#65737e;">/// Compute the band cutoff indices aligned to the block size
</span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">block_aligned_band_cutoff_indices</span><span>(
</span><span>    </span><span style="color:#bf616a;">bsize</span><span>: </span><span style="color:#b48ead;">usize</span><span>,
</span><span>    </span><span style="color:#bf616a;">center</span><span>: </span><span style="color:#b48ead;">f64</span><span>,
</span><span>    </span><span style="color:#bf616a;">bw</span><span>: </span><span style="color:#b48ead;">f64</span><span>,
</span><span>    </span><span style="color:#bf616a;">cutoff</span><span>: </span><span style="color:#b48ead;">f64</span><span>,
</span><span>    </span><span style="color:#bf616a;">xs</span><span>: &amp;[</span><span style="color:#b48ead;">f64</span><span>],
</span><span>) -&gt; (</span><span style="color:#b48ead;">usize</span><span>, </span><span style="color:#b48ead;">usize</span><span>) {
</span><span>    </span><span style="color:#b48ead;">let</span><span> lower = xs.</span><span style="color:#96b5b4;">partition_point</span><span>(|&amp;</span><span style="color:#bf616a;">x</span><span>| x &lt; (center - cutoff * bw));
</span><span>    </span><span style="color:#b48ead;">let</span><span> upper = xs.</span><span style="color:#96b5b4;">partition_point</span><span>(|&amp;</span><span style="color:#bf616a;">x</span><span>| x &lt; (center + cutoff * bw));
</span><span>    </span><span style="color:#b48ead;">let</span><span> rem = (upper - lower) % bsize;
</span><span>    </span><span style="color:#65737e;">// The higher energy side tends to have less going on, so we can err
</span><span>    </span><span style="color:#65737e;">// on the side of computing fewer values there
</span><span>    </span><span style="color:#b48ead;">return </span><span>(lower, upper - rem);
</span><span>}
</span><span>
</span><span style="color:#65737e;">/// Compute the cutoff bands using SIMD
</span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">add_cutoff_bands_chunked</span><span>(
</span><span>    </span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">spec</span><span>: ArrayViewMut1&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>    </span><span style="color:#bf616a;">energies</span><span>: ArrayView1&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>    </span><span style="color:#bf616a;">stick_strengths</span><span>: ArrayView1&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>    </span><span style="color:#bf616a;">bws</span><span>: &amp;[</span><span style="color:#b48ead;">f64</span><span>],
</span><span>    </span><span style="color:#bf616a;">cutoff</span><span>: </span><span style="color:#b48ead;">f64</span><span>,
</span><span>    </span><span style="color:#bf616a;">x</span><span>: ArrayView1&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>) {
</span><span>    </span><span style="color:#b48ead;">let</span><span> band_indices: Vec&lt;(</span><span style="color:#b48ead;">usize</span><span>, </span><span style="color:#b48ead;">usize</span><span>)&gt; = energies
</span><span>        .</span><span style="color:#96b5b4;">iter</span><span>()
</span><span>        .</span><span style="color:#96b5b4;">zip</span><span>(bws.</span><span style="color:#96b5b4;">iter</span><span>())
</span><span>        .</span><span style="color:#96b5b4;">map</span><span>(|(&amp;</span><span style="color:#bf616a;">e</span><span>, &amp;</span><span style="color:#bf616a;">b</span><span>)| {
</span><span>            </span><span style="color:#96b5b4;">block_aligned_band_cutoff_indices</span><span>(</span><span style="color:#d08770;">BLOCK_SIZE</span><span>, e, b, cutoff, x.</span><span style="color:#96b5b4;">as_slice</span><span>().</span><span style="color:#96b5b4;">unwrap</span><span>())
</span><span>        })
</span><span>        .</span><span style="color:#96b5b4;">collect</span><span>();
</span><span>    </span><span style="color:#b48ead;">let</span><span> denoms: Vec&lt;</span><span style="color:#b48ead;">f64</span><span>&gt; = bws.</span><span style="color:#96b5b4;">iter</span><span>().</span><span style="color:#96b5b4;">map</span><span>(|&amp;</span><span style="color:#bf616a;">b</span><span>| </span><span style="color:#96b5b4;">gauss_denom</span><span>(b)).</span><span style="color:#96b5b4;">collect</span><span>();
</span><span>    </span><span style="color:#b48ead;">let</span><span> x_slice = x.</span><span style="color:#96b5b4;">as_slice</span><span>().</span><span style="color:#96b5b4;">unwrap</span><span>();
</span><span>    </span><span style="color:#b48ead;">let</span><span> spec_slice = spec.</span><span style="color:#96b5b4;">as_slice_mut</span><span>().</span><span style="color:#96b5b4;">unwrap</span><span>();
</span><span>    </span><span style="color:#b48ead;">for </span><span>(&amp;e, (&amp;s, (&amp;d, bi))) in energies
</span><span>        .</span><span style="color:#96b5b4;">iter</span><span>()
</span><span>        .</span><span style="color:#96b5b4;">zip</span><span>(stick_strengths.</span><span style="color:#96b5b4;">iter</span><span>().</span><span style="color:#96b5b4;">zip</span><span>(denoms.</span><span style="color:#96b5b4;">iter</span><span>().</span><span style="color:#96b5b4;">zip</span><span>(band_indices)))
</span><span>    {
</span><span>        x_slice[bi.</span><span style="color:#d08770;">0</span><span>..bi.</span><span style="color:#d08770;">1</span><span>]
</span><span>            .</span><span style="color:#96b5b4;">chunks_exact</span><span>(</span><span style="color:#d08770;">BLOCK_SIZE</span><span>)
</span><span>            .</span><span style="color:#96b5b4;">zip</span><span>(spec_slice.</span><span style="color:#96b5b4;">chunks_exact_mut</span><span>(</span><span style="color:#d08770;">BLOCK_SIZE</span><span>))
</span><span>            .</span><span style="color:#96b5b4;">for_each</span><span>(|(</span><span style="color:#bf616a;">x_chunk</span><span>, </span><span style="color:#bf616a;">s_chunk</span><span>)| {
</span><span>                s_chunk[</span><span style="color:#d08770;">0</span><span>] += s * (-(x_chunk[</span><span style="color:#d08770;">0</span><span>] - e).</span><span style="color:#96b5b4;">powi</span><span>(</span><span style="color:#d08770;">2</span><span>) / d).</span><span style="color:#96b5b4;">exp</span><span>();
</span><span>                s_chunk[</span><span style="color:#d08770;">1</span><span>] += s * (-(x_chunk[</span><span style="color:#d08770;">1</span><span>] - e).</span><span style="color:#96b5b4;">powi</span><span>(</span><span style="color:#d08770;">2</span><span>) / d).</span><span style="color:#96b5b4;">exp</span><span>();
</span><span>                s_chunk[</span><span style="color:#d08770;">2</span><span>] += s * (-(x_chunk[</span><span style="color:#d08770;">2</span><span>] - e).</span><span style="color:#96b5b4;">powi</span><span>(</span><span style="color:#d08770;">2</span><span>) / d).</span><span style="color:#96b5b4;">exp</span><span>();
</span><span>                s_chunk[</span><span style="color:#d08770;">3</span><span>] += s * (-(x_chunk[</span><span style="color:#d08770;">3</span><span>] - e).</span><span style="color:#96b5b4;">powi</span><span>(</span><span style="color:#d08770;">2</span><span>) / d).</span><span style="color:#96b5b4;">exp</span><span>();
</span><span>            });
</span><span>    }
</span><span>}
</span></code></pre>
<p>This was actually marginally <em>slower</em>, 8.4ms vs. 8.1ms. However, it's very clear from the assembly that the operations are being vectorized. Here's a snippet where it's clear that actual math is being done:</p>
<pre data-lang="asm" style="background-color:#2b303b;color:#c0c5ce;" class="language-asm "><code class="language-asm" data-lang="asm"><span style="color:#8fa1b3;">LBB44_100:
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#8fa1b3;">xmmword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">r14</span><span>, +, </span><span style="color:#d08770;">8</span><span>*</span><span style="color:#bf616a;">rdi</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mulpd   </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#bf616a;">xmm1
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">divpd   </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#bf616a;">xmm0
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">movupd  </span><span style="color:#8fa1b3;">xmmword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbx</span><span>, +, </span><span style="color:#d08770;">8</span><span>*</span><span style="color:#bf616a;">rdi</span><span>], </span><span style="color:#bf616a;">xmm1
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#8fa1b3;">xmmword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">r14</span><span>, +, </span><span style="color:#d08770;">8</span><span>*</span><span style="color:#bf616a;">rdi</span><span>, +, </span><span style="color:#d08770;">16</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mulpd   </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#bf616a;">xmm1
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">divpd   </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#bf616a;">xmm0
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">movupd  </span><span style="color:#8fa1b3;">xmmword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbx</span><span>, +, </span><span style="color:#d08770;">8</span><span>*</span><span style="color:#bf616a;">rdi</span><span>, +, </span><span style="color:#d08770;">16</span><span>], </span><span style="color:#bf616a;">xmm1
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">add     </span><span style="color:#bf616a;">rdi</span><span>, </span><span style="color:#d08770;">4
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">add     </span><span style="color:#bf616a;">rsi</span><span>, </span><span style="color:#d08770;">2
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">jne     </span><span style="color:#8fa1b3;">LBB44_100
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">test    </span><span style="color:#bf616a;">dl</span><span>, </span><span style="color:#d08770;">1
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">je      </span><span style="color:#8fa1b3;">LBB44_103
</span><span style="color:#8fa1b3;">LBB44_102:
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm0</span><span>, </span><span style="color:#8fa1b3;">xmmword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">r14</span><span>, +, </span><span style="color:#d08770;">8</span><span>*</span><span style="color:#bf616a;">rdi</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">mulpd   </span><span style="color:#bf616a;">xmm0</span><span>, </span><span style="color:#bf616a;">xmm0
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">divpd   </span><span style="color:#bf616a;">xmm0</span><span>, </span><span style="color:#8fa1b3;">xmmword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rip</span><span>, +, </span><span style="color:#8fa1b3;">LCPI44_0</span><span>]
</span><span style="color:#8fa1b3;"> </span><span style="color:#b48ead;">movupd  </span><span style="color:#8fa1b3;">xmmword</span><span>, </span><span style="color:#96b5b4;">ptr</span><span>, [</span><span style="color:#bf616a;">rbx</span><span>, +, </span><span style="color:#d08770;">8</span><span>*</span><span style="color:#bf616a;">rdi</span><span>], </span><span style="color:#bf616a;">xmm0
</span></code></pre>
<p>Unfortunately, I don't have much insight into why this is slower. If I had to guess, I would say that it's a combination of the following:</p>
<ul>
<li>My laptop only has 128-bit floating point SIMD registers, so you're only operating on two <code>f64</code>s at a time</li>
<li>SIMD instructions have significantly higher latency than scalar instructions</li>
</ul>
<p>Perhaps the SIMD overhead outweighs the (at best) 2x speedup from using SIMD instructions?</p>
<h3 id="explicit-simd">Explicit SIMD</h3>
<p>Just for kicks I decided to try writing the SIMD code myself rather than relying on the compiler to do it for me. It's worth noting that it's not very clear to me what the current recommendation is when it comes to SIMD crates. These are the official options:</p>
<ul>
<li>The <a href="https://doc.rust-lang.org/nightly/std/simd/index.html">std::simd</a> module, only available with the Nightly compiler</li>
<li>Architecture specific implementations in the <code>std::arch</code> module, which comes from the <a href="https://github.com/rust-lang/stdarch">stdarch</a> crate</li>
<li>The <a href="https://github.com/rust-lang/packed_simd">packed_simd</a> crate</li>
</ul>
<p>In the end I decided to go with <code>packed_simd</code> because it looked the most ergonomic. It only took a slight modification of the <code>chunked</code> code to get it working with SIMD.</p>
<p>This brought execution time from 8.1ms to 7.4ms for a 9% speedup (51x overall).</p>
<p>I decided not to keep this implementation because it requires a Nightly compiler and it would require supporting different architectures (I have an Apple Silicon laptop on the way).</p>
<h3 id="cachegrind">Cachegrind</h3>
<p>I wondered if there was anything egregiously cache-inefficient, so I decided to try running a program under <a href="https://valgrind.org/docs/manual/cg-manual.html">Cachegrind</a>. Cachegrind essentially doesn't support macOS so I put together a Docker container for doing this analysis:</p>
<pre data-lang="dockerfile" style="background-color:#2b303b;color:#c0c5ce;" class="language-dockerfile "><code class="language-dockerfile" data-lang="dockerfile"><span style="color:#b48ead;">FROM</span><span> rust:latest
</span><span>
</span><span style="color:#65737e;"># Install build-time dependencies, remove cruft afterwards
</span><span style="color:#b48ead;">RUN </span><span>apt-get update &amp;&amp; apt-get install -y valgrind libopenblas-dev gfortran python3 python3-pip &amp;&amp; rm -rf /var/lib/apt/lists/*
</span><span style="color:#b48ead;">RUN </span><span>python3 -m pip install --user numpy
</span><span>
</span><span style="color:#65737e;"># Cache the Rust dependencies so they don&#39;t download on every recompile
</span><span style="color:#b48ead;">WORKDIR </span><span>/ham2spec
</span><span style="color:#b48ead;">COPY</span><span> Cargo.toml .
</span><span style="color:#b48ead;">RUN </span><span>mkdir src &amp;&amp; touch src/lib.rs &amp;&amp; cargo vendor
</span><span>
</span><span style="color:#65737e;"># Copy the code over
</span><span style="color:#b48ead;">COPY</span><span> src/ ./src/ 
</span><span style="color:#b48ead;">COPY</span><span> examples/ ./examples/
</span><span>
</span><span style="color:#65737e;"># Compile the example
</span><span style="color:#b48ead;">RUN </span><span>RUSTFLAGS=&#39;</span><span style="color:#a3be8c;">-C force-frame-pointers=y</span><span>&#39; cargo build --example multiple_broadened_spectra --release
</span></code></pre>
<p>I build and run the container:</p>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>$ docker build -t rust-cachegrind:latest .
</span><span>$ docker run -it -v &quot;$PWD/cgout&quot;:/out rust-cachegrind:latest
</span></code></pre>
<p>then run Cachegrind from inside the container:</p>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>$ valgrind --tool=cachegrind target/release/examples/multiple_broadened_spectra
</span></code></pre>
<p>Unfortunately this didn't reveal anything egregious, which is the only thing that would jump out at me since I've never used Cachegrind before.</p>
<h2 id="wrapping-up">Wrapping up</h2>
<p>I didn't get an overall speedup of 100x like I wanted, but I did get ~50x, and that's not nothing.</p>
<p>One thing that became abundantly clear to me is that being able to intuitively read assembly would help me take my understanding of my code to the next level. Another thing that became clear is that although I'm aware of a variety of tools at my disposal (Cachegrind, perf, lldb, etc), I'm not always sure how to get the most out of them. This will come with experience, so I'll keep looking for excuses to do this kind of thing.</p>
<p>That's all for now. If you have hints, guidance, or feedback, feel free to chime in! You can find my email address in the About page.</p>
<p>Update: After my laptop arrived my speedup jumped to 250x with no changes in the code. Thanks Moore's Law!</p>

</article>


      
      <footer role="contentinfo">
        <hr />
        
        <nav style="margin-bottom:1rem;" role="navigation">
          
            <a href="/">Home</a>
            
              <span>&middot;</span>
            
          
            <a href="https://github.com/zmitchell">GitHub</a>
            
              <span>&middot;</span>
            
          
            <a href="/about/">About</a>
            
          
        </nav>
        
        
        <small>
          
          
        </small>
        
      </footer>
      

    </main>
    
    
  </body>
</html>

